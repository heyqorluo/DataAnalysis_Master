---
title: "Nora Master Project Data Analysis Notebook"
author: "Nora Luo"
output:
  html_document:
    df_print: paged
---
# Table of Contents
1. [Notation](#notation)
2. [Load and split the data](#load-and-split-the-data)
3. [Screening Questions](#screening-questions)
4. [Actual Survey Analysis](#actual-survey-analysis)
5. [Statistical Testing](#statistical-testing)
6. [Skewed Data](#skewed-data)
7. [Decision-making](#decision-making)


This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code.

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*.

```{r}
plot(cars)
```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

------------------------------------------------------------------------
# README
- run the Load and split the data chunk first
- results was filtered based on Q3.9 - whether respondents understand the concept of inflation 
- ! : We can reject the null hypothesis.\


# Load and split the data <a name="load-and-split-the-data"></a>

```{r}
library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(FSA)
library(car)
library(rstatix)   
library(effectsize) 



exported_data <- read_csv("final_rawdata_value_1605.csv")
exported_data <- subset(exported_data, select = -c(StartDate,EndDate,Status,IPAddress,Progress,Finished,RecordedDate, RecipientLastName,RecipientFirstName,                                  RecipientEmail,ExternalReference,LocationLatitude,LocationLongitude,DistributionChannel,UserLanguage))
rawdata_value <- subset(exported_data, select =-c(ResponseId,Q1.1,Q2.1))
rawdata_value <- rawdata_value[3:nrow(rawdata_value), ]

# label the group
rawdata_value <- rawdata_value %>%
  mutate(group = case_when(
    !is.na(Q4.2)  ~ '0-controlled',
    !is.na(Q6.2)  ~ '1-errorbar',
    !is.na(Q8.2)  ~ '2-shadedbar',
    !is.na(Q10.2) ~ '3-fanchartslice',
    !is.na(Q12.2) ~ '4-bellcurve'
  ),
  treatment = case_when(
    group %in% c("1-errorbar","2-shadedbar","3-fanchartslice","4-bellcurve")
      ~ "treatment_group",
     TRUE
      ~ as.character(group)     # or another fallback
  ))
# create a copy of the data for Q3.9 analysis
rawdata_q3_9 <- rawdata_value
# filter participants who do not understand the concept of inflation
rawdata_value <- rawdata_value[rawdata_value$Q3.9 == "4", ]

# rawdata_value <- rawdata_value %>%
#   mutate(group = case_when(
#     !is.na(Q4.2)  ~ 0,
#     !is.na(Q6.2)  ~ 1,
#     !is.na(Q8.2)  ~ 2,
#     !is.na(Q10.2) ~ 3,
#     !is.na(Q12.2) ~ 4
#   ))

# meta-data
total_respondents <- nrow(rawdata_value)


group_total <- rawdata_value %>%
  group_by(group) %>%
  summarise(n_respondents = n())

total_treatment_respodents <- total_respondents - group_total$n_respondents[1]
  
  
# graph preparation

likelihood_labels = c(
    "9" = "Exceptionally unlikely",
    "10" = "Very unlikely",
    "11" = "Quite unlikely",
    "12" = "Fifty-fifty",
    "13" = "Quite likely",
    "14" = "Very likely",
    "15" = "Virtually certain"
  )

# filter treatment groups
controlled_group <- rawdata_value[!is.na(rawdata_value$Q4.2), ]
error_bar <-rawdata_value[!is.na(rawdata_value$Q6.2), ]
shaded_bar <-rawdata_value[!is.na(rawdata_value$Q8.2), ]
fanchart_slice <-rawdata_value[!is.na(rawdata_value$Q10.2), ]
bell_curve <-rawdata_value[!is.na(rawdata_value$Q12.2), ]

# adding labels to the groups
# controlled_group$group <- 1
# error_bar$group <- 2
# shaded_bar$group <- 3
# fanchart_slice$group <- 4
# bell_curve$group <- 5


# remove unnecessary columns
controlled_group = controlled_group[,grepl("^(Q3|Q4|Q5)",names(controlled_group))|names(controlled_group) %in% c("Duration (in seconds)", "group","treatment")]
error_bar = error_bar[,grepl("^(Q3|Q6|Q7)",names(error_bar))| names(error_bar) %in% c("Duration (in seconds)", "group","treatment")]
shaded_bar = shaded_bar[,grepl("^(Q3|Q8|Q9)",names(shaded_bar))| names(shaded_bar)%in% c("Duration (in seconds)", "group","treatment")]
fanchart_slice = fanchart_slice[,grepl("^(Q3|Q10|Q11)",names(fanchart_slice))| names(fanchart_slice) %in% c("Duration (in seconds)", "group","treatment")]
bell_curve = bell_curve[,grepl("^(Q3|Q12|Q13)",names(bell_curve))| names(bell_curve) %in% c("Duration (in seconds)", "group","treatment")]
# controlled_group = controlled_group[,!sapply(controlled_group, function(x) mean(is.na(x)))>0.9]

group_list <- list(
  controlled = controlled_group,
  errorbar = error_bar,
  shadedbar = shaded_bar,
  fanchartslice = fanchart_slice,
  bellcurve = bell_curve
)

skewed_group_list <- group_list[-1]

```

 
# Screening Questions <a name="screening-questions"></a>

## ! Time Duration
Variable: continuous <br> 
Method: check normality + kruskal-wallis test + post-hoc test\
**Result: p\< 0.05--\> we can reject the hypothesis** <br> controlled group is significantly different from (error bar; shaded bar; fanchart slice; BUT NOT fanchartslice)
```{r}
time_duration_table <- rawdata_value[,c("Duration (in seconds)", "group")]
time_duration_table$`Duration (in mins)` <- as.numeric(time_duration_table$`Duration (in seconds)`)/60

# report quantile information
summary(time_duration_table$`Duration (in mins)`)


# test for normality --> It's definitely not normal distribution
# shapiro.test(time_duration_table$`Duration (in mins)`)

# run the kruskal-wallis test
kruskal_test <- kruskal.test(`Duration (in mins)` ~ group, data = time_duration_table)
print(kruskal_test)

# run post-hoc test
dunn_test <- dunnTest(`Duration (in mins)` ~ group, data = time_duration_table, method = "bonferroni")
print(dunn_test)

```

Time duration summary table

```{r}
time_duration_summary <- time_duration_table %>%
  group_by(group) %>%
  summarise(mean_duration = mean(`Duration (in mins)`, na.rm = TRUE), 
            sd_duration = sd(`Duration (in mins)`, na.rm = TRUE),
            .groups = 'drop')
```

Plot the distribution of different groups
```{r}
# density plot
ggplot(time_duration_table, aes(x = `Duration (in mins)`, fill = group)) +
  geom_density(alpha = 0.3) +
  # facet_wrap(~ group, scales = "free") +
  labs(title = "Duration Density by Group",
       x = "Duration",
       y = "Density") +
  theme_minimal()


# histogram
ggplot(time_duration_table, aes(x = `Duration (in mins)`)) +
  geom_histogram(binwidth = 1, fill = "steelblue", color = "white") +
  facet_wrap(~ group) +
  labs(title = "Distribution of Duration by Group",
       x = "Duration (e.g. in minutes)",
       y = "Count") +
  scale_x_continuous(breaks = seq(0, max(time_duration_table$`Duration (in mins)`, na.rm = TRUE), by = 10)) +
  theme_minimal()

```


Plot time duration bar chart. It's not valid as the data is not normal distribution.

```{r}
ggplot(time_duration_summary, aes(x = group, y = mean_duration)) +
  geom_bar(stat = "identity", fill = "steelblue", width = 0.6) +
  geom_errorbar(aes(ymin = mean_duration - sd_duration, ymax = mean_duration + sd_duration), width = 0.2) +
  labs(title = "Response Duration by Group",
       y = "Duration (in minutes)",
       x = "Group") +
  theme_minimal()
```

## Q3.2 Age
What is your age? <br> 
Variable: continuous <br> 
Method: kruskal-wallis test <br> 
**Result: Fail to reject the null hypothesis**
```{r}
age_table <- rawdata_value[, c("Q3.2", "group")]
age_table$`Q3.2` <- as.numeric(gsub("[^0-9.]", "", age_table$`Q3.2`))

# test for normality
# shapiro.test(age_table$`Q3.2`)
# bartlett.test(`Q3.2` ~ group, data = age_table)


# run the kruskal-wallis test
kruskal_test <- kruskal.test(`Q3.2` ~ group, data = age_table)
print(kruskal_test)

age_summary <- age_table %>%
  group_by(group) %>%
  summarise(mean_age = mean(`Q3.2`, na.rm = TRUE), 
            sd_age = sd(`Q3.2`, na.rm = TRUE),
            .groups = 'drop')
```

## Q3.3 Gender
Which of the following best describes your gender identity? <br> 
Variable: categorical <br> 
Method: contingency Table + chi-squared test <br> 
**Result: Fail to reject the null hypothesis**
```{r}
q3_3_table <- rawdata_value[, c("Q3.3", "group")]
# q3_3_table$Q3.3 <- recode(q3_3_table$Q3.3,
#                                     "1" = "Male",
#                                     "2" = "Female",
#                                     .default = "Other")
q3_3_contingency <- table(q3_3_table$Q3.3, q3_3_table$group)
print(q3_3_contingency)

# Chi-squared test
chisq.test(q3_3_contingency)

```

Calculate the gender percentage

```{r}
# percentage of male
male_per <- q3_3_contingency[1,]
gender_group_total <- colSums(q3_3_contingency)
male_prop <- male_per/gender_group_total

```

## Q3.4 Highest Education
What is your highest level of education achieved?\
Variable: categorical with written insights from choice 9
Method: contingency Table + chi-squared test\
**Result: Fail to reject the null hypothesis**

```{r}
q3_4_table <- rawdata_value[rawdata_value$`Q3.4` != "9", c("Q3.4", "group")]

q3_4_contingency <- table(q3_4_table$Q3.4, q3_4_table$group)
# Chi-squared test
chisq.test(q3_4_contingency)

```
Highest Education Level proportion bar plot across different groups
```{r}

q3_4_prop  <- as.data.frame(q3_4_contingency)
# rename columns
names(q3_4_prop) <- c("Q3.4", "Group", "Count")

# calculate proportions within each group
q3_4_prop <- q3_4_prop %>%
  group_by(Group) %>%
  mutate(Proportion = Count / sum(Count))

ggplot(q3_4_prop, aes(x = as.factor(`Q3.4`), y = Proportion, fill = Group)) +
  geom_bar(stat = "identity", position = "dodge") +
  # facet_wrap(~ Group) +
  labs(
    title = "Q3.4 Highest Education Level Propotion Plot across Groups",
    x = "Response",
    y = "Proportion"
  ) +
  # scale_x_discrete(labels = c(
  #   "1" = "No formal education",
  #   "2" = "Primary/Elementary",
  #   "3" = "Secondary School (GCSE)",
  #   "4" = "High School (A Level)",
  #   "5" = "Technical or Vocational",
  #   "6" = "Bachelors or equivalent degree level qualification",
  #   "7" = "Masters or equivalent higher degree level qualification",
  #   "8" = "PhD or equivalent doctoral level qualification"))+
   scale_fill_brewer(palette = "Set2")+
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Plot pie chart including all participants
```{r}
q3_4_table <- rawdata_value[, c("Q3.4", "group")]

# Q3.4 summary table
q3_4_summary <- q3_4_table %>%
  group_by(`Q3.4`) %>%
  summarise(count = n()) %>%
  mutate(proportion = count / sum(count),
         label = 
            case_when(
              Q3.4 == "1" ~ "1-No formal education",
              Q3.4 == "2" ~ "2-Primary/Elementary",
              Q3.4 == "3" ~ "3-Secondary School (GCSE)",
              Q3.4 == "4" ~ "4-High School (A Level)",
              Q3.4 == "5" ~ "5-Technical or Vocational",
              Q3.4 == "6" ~ "6-Bachelors or equivalent degree level qualification",
              Q3.4 == "7" ~ "7-Masters or equivalent higher degree level qualification",
              Q3.4 == "8" ~ "8-PhD or equivalent doctoral level qualification",
              Q3.4 == "9" ~ "9-Other"
            ),
         label = paste0(label, " (", round(proportion * 100, 2), " %)")
         )

ggplot(q3_4_summary, aes(x = "",y = proportion, fill = label)) +
  geom_col(width = 1) +
  coord_polar(theta = "y") +
  labs(title = "Q3.4 Highest Education Level Summary Pie Chart",
       x = "",
       y = "") +
  theme_minimal() +
  theme(axis.text.x = element_blank())

```



## Q3.5 Employee Status
What is your current profession or employment status?\
Variable: categorical\
Method: contingency Table + chi-squared test\
**Result: Fail to reject the null hypothesis**
```{r}
q3_5_table <- rawdata_value[rawdata_value$`Q3.5` != "6", c("Q3.5", "group")]
q3_5_contingency <- table(q3_5_table$Q3.5, q3_5_table$group)
# print(q3_5_contingency)

# Chi-squared test
chisq.test(q3_5_contingency)

```

Employee status proportion bar plot across different groups

```{r}
q3_5_prop  <- as.data.frame(q3_5_contingency)
# rename columns
names(q3_5_prop) <- c("Q3.5", "Group", "Count")


# calculate proportions within each group
q3_5_prop <- q3_5_prop %>%
  group_by(Group) %>%
  mutate(Proportion = Count / sum(Count))

ggplot(q3_5_prop, aes(x = as.factor(`Q3.5`), y = Proportion, fill = Group)) +
  geom_bar(stat = "identity", position = "dodge") +
  # facet_wrap(~ Group) +
  labs(
    title = "Q3.5 Employee Status Propotion Plot across Groups",
    x = "Response",
    y = "Proportion"
  ) +
  scale_x_discrete(labels = c(
    "1" = "Student",
    "2" = "Employed",
    "3" = "Self-employed",
    "4" = "Retired",
    "5" = "Unemployed"
  )) +
   scale_fill_brewer(palette = "Set2")+
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Plot pie chart including all participants
```{r}
q3_5_table <- rawdata_value[, c("Q3.5", "group")]
q3_5_summary <- q3_5_table %>%
  group_by(`Q3.5`) %>%
  summarise(count = n()) %>%
  mutate(proportion = count / sum(count),
         label = 
            case_when(
              Q3.5 == "1" ~ "1-Student",
              Q3.5 == "2" ~ "2-Employed",
              Q3.5 == "3" ~ "3-Self-employed",
              Q3.5 == "4" ~ "4-Retired",
              Q3.5 == "5" ~ "5-Unemployed",
              Q3.5 == "6" ~ "6-Other"
            ),
         label = paste0(label, " (", round(proportion * 100, 2), " %)")
         )
ggplot(q3_5_summary, aes(x = "",y = proportion, fill = label)) +
  geom_col(width = 1) +
  coord_polar(theta = "y") +
  labs(title = "Q3.5 Employee Status Summary Pie Chart",
       x = "",
       y = "") +
  theme_minimal() +
  theme(axis.text.x = element_blank())
```




## Q3.6 Economics Education
In which, if any, have you ever studied economics? (Select all that apply)\
Variable: categorical\
Method: convert to list and count + chi-squared test\
**Result: Fail to reject the null hypothesis**


Plot percentage bar chart including all participants
```{r}
q3_6_table <- rawdata_value[, c("Q3.6", "group")]
q3_6_table$Q3.6 <- lapply(q3_6_table$Q3.6, function(x) as.list(as.numeric(strsplit(x, ",")[[1]])))

# count the number of occurrences of each value
q3_6_summary <- q3_6_table %>%
  unnest(Q3.6) %>%
  group_by(`Q3.6`) %>%
  summarise(count = n()) %>%
  mutate(proportion = count / total_respondents,
         label = 
            case_when(
              Q3.6 == "1" ~ "1-At school",
              Q3.6 == "2" ~ "2-In higher education",
              Q3.6 == "3" ~ "3-Through self-directed study",
              Q3.6 == "4" ~ "4-Self-motivated study",
              Q3.6 == "5" ~ "5-Never studied economics",
              Q3.6 == "6" ~ "6-Don’t know / can’t recall",
              Q3.6 == "7" ~ "7-Other"
            ))

# q3_6_summary$Q3.6 <- as.numeric(q3_6_summary$Q3.6)
ggplot(q3_6_summary, aes(x = factor(label), y = proportion)) +
  geom_col(fill = "steelblue") +
  geom_text(aes(label = paste0(round(proportion * 100, 1), "%")), 
            vjust = -0.2) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  labs(
    title = "Percentage of Participants Selecting Each Q3.6 Option",
    x = "Response",
    y = "Percentage of Participants"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```





```{r}
q3_6_table <- rawdata_value[, c("Q3.6", "group")]
q3_6_table$Q3.6 <- lapply(q3_6_table$Q3.6, function(x) as.list(as.numeric(strsplit(x, ",")[[1]])))
# count the number of occurrences of each value
q3_6_prop <- q3_6_table %>%
  unnest(Q3.6) %>%
  group_by(group, Q3.6) %>%
  summarise(count = n(), .groups = 'drop')
q3_6_prop$Q3.6 <- as.numeric(q3_6_prop$Q3.6)

# create a contingency table
q3_6_contingency <- xtabs(count ~ Q3.6 + group, data = q3_6_prop)
print(q3_6_contingency)

# Chi-squared test
chisq.test(q3_6_contingency)

# q3_6_test <-q3_6_prop %>%
#   group_by(`Q3.6`) %>%
#   summarise(total_count = sum(count), .groups = "drop")

```

Economics Education proportion bar plot across different groups
```{r}
# convert contingency table to data frame # count 0 as well
q3_6_prop <- as.data.frame(q3_6_contingency)
# calculate proportions within each group
q3_6_prop <- q3_6_prop %>%
  left_join(group_total, by = "group") %>%
  mutate(Proportion = Freq / n_respondents)

ggplot(q3_6_prop, aes(x = factor(Q3.6), y = Proportion, fill = factor(group))) +
  geom_col(position = "dodge") +
  labs(
    title = "Q3.6 Economics Education Propotion Plot across Groups",
    x = "Response",
    y = "Proportion",
    fill = "Group"
  ) +
  scale_fill_brewer(palette = "Set2")+
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_minimal()
```



## Q3.7 Financial Activities
Which of the following financial activities do you actively participate in? (Select all that apply) - Selected Choice Fixed Income (e.g., government bonds, corporate bonds)\
Variable: categorical\
Method: convert to list and count + chi-squared test\
**Result: Fail to reject the null hypothesis**
```{r}
q3_7_table <- rawdata_value[, c("Q3.7", "group")]
q3_7_table$Q3.7 <- lapply(q3_7_table$Q3.7, function(x) as.list(as.numeric(strsplit(x, ",")[[1]])))
# count the number of occurrences of each value in each group
q3_7_prop <- q3_7_table %>%
  unnest(Q3.7) %>%
  group_by(group,`Q3.7`) %>%
  summarise(count = n(), .groups = 'drop')
q3_7_prop$Q3.7 <- as.numeric(q3_7_prop$Q3.7)

# create a contingency table
q3_7_contingency <- xtabs(count ~ `Q3.7` + group, data = q3_7_prop)
print(q3_7_contingency)
# Chi-squared test
chisq.test(q3_7_contingency)

```

Plot financial activities proportion bar plot across different groups
```{r}
# convert contingency table to data frame
q3_7_prop <- as.data.frame(q3_7_contingency) %>%
  left_join(group_total, by = "group") %>%
  mutate(Proportion = Freq / n_respondents)


ggplot(q3_7_prop, aes(x = factor(`Q3.7`), y = Proportion, fill = factor(group))) + 
  geom_col(position = "dodge") +
  labs(
    title = "Q3.7 Financial Activities Propotion Plot across Groups",
    x = "Response",
    y = "Proportion",
    fill = "Group"
  ) +
    scale_x_discrete(labels = c(
    "11" = "Savings",
    "12" = "Investments",
    "13" = "Fixed Income",
    "14" = "Retirement Planning",
    "15" = "Trading",
    "16" = "Real Estate",
    "17" = "Cryptocurrencies",
    "18" = "None of the above",
    "19" = "Other"
      )) +
  scale_fill_brewer(palette = "Set2")+
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```
Plot percentage bar chart including all participants
```{r}
q3_7_summary <-q3_7_prop %>%
  group_by(`Q3.7`) %>%
  summarise(total_count = sum(Freq), .groups = "drop") %>%
  mutate(proportion = total_count / total_respondents,
         label = 
            case_when(
              `Q3.7` == "11" ~ "11-Savings",
              `Q3.7` == "12" ~ "12-Investments",
              `Q3.7` == "13" ~ "13-Fixed Income",
              `Q3.7` == "14" ~ "14-Retirement Planning",
              `Q3.7` == "15" ~ "15-Trading",
              `Q3.7` == "16" ~ "16-Real Estate",
              `Q3.7` == "17" ~ "17-Cryptocurrencies",
              `Q3.7` == "18" ~ "18-None of the above",
              `Q3.7` == "19" ~ "19-Other"
            ))

ggplot(q3_7_summary, aes(x = factor(label), y = proportion)) +
  geom_col(fill = "steelblue") +
  geom_text(aes(label = paste0(round(proportion * 100, 1), "%")), 
            vjust = -0.3, size = 3.5) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  labs(
    title = "Percentage of Participants Selecting Each Q3.7 Option",
    x = "Response",
    y = "Percentage of Participants"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```
## Q3.8 Awareness of Economics
How frequently, if at all, do you read/watch/listen to news stories related to economics or the economy?\
Variable: categorical\
Method: contingency table + chi-squared test\
**Result: Fail to reject the null hypothesis**
```{r}
q3_8_table <- rawdata_value[, c("Q3.8", "group")]

q3_8_contingency <- table(q3_8_table$Q3.8, q3_8_table$group)
print(q3_8_contingency)
# Chi-squared test
# chisq.test(q3_8_contingency)
chisq.test(q3_8_contingency[-nrow(q3_8_contingency), ])

```
Awareness of Economics proportion bar plot across different groups
```{r}
q3_8_prop  <- as.data.frame(q3_8_contingency)
# rename columns
names(q3_8_prop) <- c("Q3.8", "Group", "Count")

# add a labelled column
q3_8_prop <- q3_8_prop %>%
  mutate(Q3.8_label = case_when(
    Q3.8 == "1" ~ "1-Never",
    Q3.8 == "2" ~ "2-Rarely",
    Q3.8 == "3" ~ "3-Monthly",
    Q3.8 == "4" ~ "4-Weekly",
    Q3.8 == "5" ~ "5-Almost daily",
    Q3.8 == "6" ~ "6-Every day",
    Q3.8 == "7" ~ "7-Not sure"
  ))

# calculate proportions within each group
q3_8_prop <- q3_8_prop %>%
  group_by(Group) %>%
  mutate(Proportion = Count / sum(Count))

ggplot(q3_8_prop, aes(x = as.factor(`Q3.8_label`), y = Proportion, fill = Group)) +
  geom_col(position = "dodge") +
  # facet_wrap(~ Group) +
  labs(
    title = "Q3.8 Awareness of Economics Propotion Plot across Groups",
    x = "Response",
    y = "Proportion"
  ) +
   scale_fill_brewer(palette = "Set2")+
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Plot pie chart including all participants
```{r}
q3_8_summary <- q3_8_prop %>%
  group_by(`Q3.8_label`) %>%
  summarise(total_count = sum(Count), .groups = "drop") %>%
  mutate(proportion = total_count / sum(total_count),
        `Q3.8_label` = paste0(`Q3.8_label`, " (", round(proportion * 100, 2), " %)"))
ggplot(q3_8_summary, aes(x = "",y = proportion, fill = `Q3.8_label`)) +
  geom_col(width = 1) +
  coord_polar(theta = "y") +
  labs(title = "Q3.8 Awareness of Economics Summary Pie Chart",
       x = "",
       y = "") +
  theme_minimal() +
  theme(axis.text.x = element_blank())
```

## Q3.9 Inflation Knowledge
To the best of your knowledge, which option most accurately describes what inflation is?\
Definitive correct answer\
Variable: categorical\
Method: descriptive analysis\
**Respondents were filtered based on whether if they can understand what inflation is.**\

```{r}
q3_9_table <- rawdata_q3_9[, c("Q3.9", "group")]
q3_9_summary <- q3_9_table %>%
  group_by(`Q3.9`) %>%
  summarise(count = n()) %>%
  mutate(proportion = count / sum(count))

  ggplot(q3_9_summary, aes(x = "",y = proportion, fill = `Q3.9`)) +
  geom_col(width = 1) +
  coord_polar(theta = "y") +
  labs(title = "Q3.9 Inflation Knowledge Summary Pie Chart",
       x = "",
       y = "") +
  theme_minimal() +
  theme(axis.text.x = element_blank())

```

## Q3.11 Trust of Official Data
How much do you trust official inflation forecasts (For instance, the forecasts released by the Bank of England)?\
*ascending value-increasing trust + exclude 6- Unsure / no opinion*\
Variable: treat as continuous\
Method: Kruskal-Wallis test\
**Result: Fail to reject the null hypothesis**

```{r}
q3_11_table <- rawdata_value[rawdata_value$`Q3.11` != "6", c("Q3.11", "group")]
q3_11_table$Q3.11 <- as.numeric(q3_11_table$`Q3.11`)
# check normality --> Not normally distributed
# shapiro.test(q3_11_table$Q3.11)
# bartlett.test(`Q3.11` ~ group, data = q3_11_table)


# run kruskal test
kruskal_test <- kruskal.test(Q3.11 ~ group, data = q3_11_table)
print(kruskal_test)

q3_11_summary <- q3_11_table %>%
  group_by(group) %>%
  summarise(q3_11_mean = mean(as.numeric(Q3.11), na.rm = TRUE),
            q3_11_sd = sd(as.numeric(Q3.11), na.rm = TRUE),
            .groups = 'drop')

# report quantile information
summary(q3_11_table$Q3.11)



```
Plot the distribution of different groups
```{r}
# histogram including all participants
ggplot(q3_11_table, aes(x = Q3.11)) +
  geom_histogram(binwidth = 1, fill = "steelblue", color = "white") +
  # facet_wrap(~ group) +
  labs(title = "Q3.11 Trust official inflation forecasts distribution",
       x = "Q3.11",
       y = "Count") +
  scale_x_continuous(breaks = seq(0, max(q3_11_table$Q3.11, na.rm = TRUE), by = 1)) +
  theme_minimal()

# Grouped bar-style histogram
ggplot(q3_11_table, aes(x = factor(Q3.11), fill = factor(group))) +
  geom_bar(position = "dodge") +
  labs(
    title = "Q3.11 Trust official inflation forecasts distribution by group",
    x = "Q3.11 Response",
    y = "Count",
    fill = "Group"
  ) +
  theme_minimal()

```



 


## Q3.12 Frequency of Checking Current Inflation
How often do you check the current value of inflation?
Variable: categorical\
Method: contingency table + chi-squared test\
**Result: Fail to reject the null hypothesis**
```{r}
# Initial Check
summary(as.numeric(rawdata_value$Q3.12))

q3_12_table <- rawdata_value[, c("Q3.12", "group")]
q3_12_contingency <- table(q3_12_table$Q3.12, q3_12_table$group)
print(q3_12_contingency)
# Chi-squared test
chisq.test(q3_12_contingency)

```
Frequency of Checking Current Inflation proportion bar plot across different groups
```{r}
q3_12_prop  <- as.data.frame(q3_12_contingency)
# rename columns
names(q3_12_prop) <- c("Q3.12", "Group", "Count")

# add a labelled column
q3_12_prop <- q3_12_prop %>%
  mutate(Q3.12_label = case_when(
    Q3.12 == "1" ~ "1-Never",
    Q3.12 == "2" ~ "2-Rarely",
    Q3.12 == "3" ~ "3-Sometimes",
    Q3.12 == "4" ~ "4-Often"
  ))
# calculate proportions within each group
q3_12_prop <- q3_12_prop %>%
  group_by(Group) %>%
  mutate(Proportion = Count / sum(Count))

ggplot(q3_12_prop, aes(x = as.factor(`Q3.12_label`), y = Proportion, fill = Group)) + geom_col(position = "dodge") +
  labs(
    title = "Q3.12 Frequency of Checking Current Inflation Propotion Plot across Groups",
    x = "Response",
    y = "Proportion"
  ) +
   scale_fill_brewer(palette = "Set2")+
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
```
Plot pie chart including all participants
```{r}
q3_12_summary <- q3_12_prop %>%
  group_by(`Q3.12_label`) %>%
  summarise(total_count = sum(Count), .groups = "drop") %>%
  mutate(proportion = total_count / sum(total_count),
         `Q3.12_label` = paste0(`Q3.12_label`, " (", round(proportion * 100, 2), " %)"))
ggplot(q3_12_summary, aes(x = "",y = proportion, fill = `Q3.12_label`)) +
  geom_col(width = 1) +
  coord_polar(theta = "y") +
  labs(title = "Q3.12 Frequency of Checking Current Inflation Summary Pie Chart",
       x = "",
       y = "") +
  theme_minimal() +
  theme(axis.text.x = element_blank())
```


## Q3.13 Source of Current Inflation
Which source do you rely on to inform yourself about the current value of inflation?\
Variable: categorical\
Method: convert to list and count + chi-squared test\
**Result: Fail to reject the null hypothesis**
```{r}
q3_13_table <- rawdata_value[, c("Q3.13", "group")]
q3_13_table$Q3.13 <- lapply(q3_13_table$Q3.13, function(x) as.list(as.numeric(strsplit(x, ",")[[1]])))
# count the number of occurrences of each value
q3_13_prop <- q3_13_table %>%
  unnest(Q3.13) %>%
  group_by(group,`Q3.13`) %>%
  summarise(count = n(), .groups = 'drop')
q3_13_prop$Q3.13 <- as.numeric(q3_13_prop$Q3.13)
# create a contingency table
q3_13_contingency <- xtabs(count ~ `Q3.13` + group, data = q3_13_prop)
print(q3_13_contingency)
# Chi-squared test
chisq.test(q3_13_contingency)
```
Plot source of current inflation proportion bar plot across different groups
```{r}
# convert contingency table to data frame
q3_13_prop <- as.data.frame(q3_13_contingency) %>%
  left_join(group_total, by = "group") %>%
  mutate(Proportion = Freq / n_respondents)

# add a labelled column
q3_13_prop <- q3_13_prop %>%
  mutate(Q3.13_label = case_when(
    `Q3.13` == "1" ~ "1-Television, radio or print media",
    `Q3.13` == "2" ~ "2-Social media",
    `Q3.13` == "3" ~ "3-Official websites or data releases",
    `Q3.13` == "4" ~ "4-Content platform",
    `Q3.13` == "5" ~ "5-Actively search on search engines",
    `Q3.13` == "6" ~ "6-Family or friends",
    `Q3.13` == "7" ~ "7-Financial advice websites/forums",
    `Q3.13` == "8" ~ "8-Private banks or economic research institutes",
    `Q3.13` == "9" ~ "9-Other"
  ))
ggplot(q3_13_prop, aes(x = factor(`Q3.13_label`), y = Proportion, fill = group)) +
  geom_col(position = "dodge") +
  labs(
    title = "Q3.13 Source of Current Inflation Propotion Plot across Groups",
    x = "Response",
    y = "Proportion",
    fill = "Group"
  ) +
   scale_fill_brewer(palette = "Set2")+
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```
Plot percentage bar chart including all participants
```{r}
q3_13_summary <- q3_13_prop %>%
  group_by(`Q3.13_label`) %>%
  summarise(total_count = sum(Freq), .groups = "drop") %>%
  mutate(proportion = total_count / total_respondents)

ggplot(q3_13_summary, aes(x = factor(Q3.13_label), y = proportion)) +
  geom_col(fill = "steelblue") +
  geom_text(aes(label = paste0(round(proportion * 100, 1), "%")), 
            vjust = -0.3, size = 3.5) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  labs(
    title = "Percentage of Participants Selecting Each Q3.13 Option",
    x = "Response",
    y = "Percentage of Participants"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

## Q3.14 Impact of Current Inflation
To what extent do you feel that the current value of inflation is impacting your personal finances?
Variable: categorical\
Method: contingency table + chi-squared test\
**Result: Fail to reject the null hypothesis**
```{r}
# Initial Check
summary(as.numeric(rawdata_value$Q3.14))
q3_14_table <- rawdata_value[, c("Q3.14", "group")]
q3_14_contingency <- table(q3_14_table$Q3.14, q3_14_table$group)
print(q3_14_contingency)
# Chi-squared test
chisq.test(q3_14_contingency)

```
Impact of Current Inflation proportion bar plot across different groups
```{r}
q3_14_prop  <- as.data.frame(q3_14_contingency)
# rename columns
names(q3_14_prop) <- c("Q3.14", "Group", "Count")
# add a labelled column
q3_14_prop <- q3_14_prop %>%
  mutate(Q3.14_label = case_when(
    Q3.14 == "1" ~ "1-Not at all",
    Q3.14 == "2" ~ "2-Slightly",
    Q3.14 == "3" ~ "3-Moderately",
    Q3.14 == "4" ~ "4-Very significantly"
  ))
# calculate proportions within each group
q3_14_prop <- q3_14_prop %>%
  group_by(Group) %>%
  mutate(Proportion = Count / sum(Count))
ggplot(q3_14_prop, aes(x = as.factor(`Q3.14_label`), y = Proportion, fill = Group)) + geom_col(position = "dodge") +
  labs(
    title = "Q3.14 Impact of Current Inflation Propotion Plot across Groups",
    x = "Response",
    y = "Proportion"
  ) +
   scale_fill_brewer(palette = "Set2")+
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```
Plot pie chart including all participants
```{r}
q3_14_summary <- q3_14_prop %>%
  group_by(`Q3.14_label`) %>%
  summarise(total_count = sum(Count), .groups = "drop") %>%
  mutate(proportion = total_count / sum(total_count),
        `Q3.14_label` = paste0(`Q3.14_label`, " (", round(proportion * 100, 2), " %)"))
ggplot(q3_14_summary, aes(x = "",y = proportion, fill = `Q3.14_label`)) +
  geom_col(width = 1) +
  coord_polar(theta = "y") +
  labs(title = "Q3.14 Impact of Current Inflation Summary Pie Chart",
       x = "",
       y = "") +
  theme_minimal() +
  theme(axis.text.x = element_blank())
```

## Q3.15 Response to Current Inflation
How much do you adjust or take action in response to the change in current value of inflation?\
Variable: categorical\
Method: contingency table + chi-squared test\
**Result: Fail to reject the null hypothesis**
```{r}
# Initial Check
summary(as.numeric(rawdata_value$Q3.15))
q3_15_table <- rawdata_value[, c("Q3.15", "group")]
q3_15_contingency <- table(q3_15_table$Q3.15, q3_15_table$group)
print(q3_15_contingency)
# Chi-squared test
chisq.test(q3_15_contingency)

```
Response to Current Inflation proportion bar plot across different groups
```{r}
q3_15_prop  <- as.data.frame(q3_15_contingency)
# rename columns
names(q3_15_prop) <- c("Q3.15", "Group", "Count")
# add a labelled column
q3_15_prop <- q3_15_prop %>%
  mutate(Q3.15_label = case_when(
    Q3.15 == "1" ~ "1-Not at all",
    Q3.15 == "2" ~ "2-Rarely",
    Q3.15 == "3" ~ "3-Somewhat actively",
    Q3.15 == "4" ~ "4-Very actively"
  ))
# calculate proportions within each group
q3_15_prop <- q3_15_prop %>%
  group_by(Group) %>%
  mutate(Proportion = Count / sum(Count))
ggplot(q3_15_prop, aes(x = as.factor(`Q3.15_label`), y = Proportion, fill = Group)) + geom_col(position = "dodge") +
  labs(
    title = "Q3.15 Response to Current Inflation Propotion Plot across Groups",
    x = "Response",
    y = "Proportion"
  ) +
   scale_fill_brewer(palette = "Set2")+
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
Plot pie chart including all participants
```{r}
q3_15_summary <- q3_15_prop %>%
  group_by(`Q3.15_label`) %>%
  summarise(total_count = sum(Count), .groups = "drop") %>%
  mutate(proportion = total_count / sum(total_count),
         `Q3.15_graph_label` = paste0(`Q3.15_label`, " (", round(proportion * 100, 2), " %)"))
ggplot(q3_15_summary, aes(x = "",y = proportion, fill = `Q3.15_graph_label`)) +
  geom_col(width = 1) +
  coord_polar(theta = "y") +
  labs(title = "Q3.15 Response to Current Inflation Summary Pie Chart",
       x = "",
       y = "") +
  theme_minimal() +
  theme(axis.text.x = element_blank())

```

## Q3.16 Frequency of Checking Inflation Forecasts
How often do you look at inflation forecasts (that is, information about future inflation)?\
Variable: categorical\
Method: contingency table + chi-squared test\
**Result: Fail to reject the null hypothesis**
```{r}
# Initial Check
summary(as.numeric(rawdata_value$Q3.16))

q3_16_table <- rawdata_value[, c("Q3.16", "group")]
q3_16_contingency <- table(q3_16_table$Q3.16, q3_16_table$group)
print(q3_16_contingency)
# Chi-squared test
chisq.test(q3_16_contingency)

```
Frequency of Checking Inflation Forecasts proportion bar plot across different groups
```{r}
q3_16_prop  <- as.data.frame(q3_16_contingency)
# rename columns
names(q3_16_prop) <- c("Q3.16", "Group", "Count")
# add a labelled column
q3_16_prop <- q3_16_prop %>%
  mutate(Q3.16_label = case_when(
    Q3.16 == "1" ~ "1-Never",
    Q3.16 == "2" ~ "2-Rarely",
    Q3.16 == "3" ~ "3-Sometimes",
    Q3.16 == "4" ~ "4-Often"
  ))
# calculate proportions within each group
q3_16_prop <- q3_16_prop %>%
  group_by(Group) %>%
  mutate(Proportion = Count / sum(Count))
ggplot(q3_16_prop, aes(x = as.factor(`Q3.16_label`), y = Proportion, fill = Group)) + geom_col(position = "dodge") +
  labs(
    title = "Q3.16 Frequency of Checking Inflation Forecasts Propotion Plot across Groups",
    x = "Response",
    y = "Proportion"
  ) +
   scale_fill_brewer(palette = "Set2")+
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
Plot pie chart including all participants
```{r}
q3_16_summary <- q3_16_prop %>%
  group_by(`Q3.16_label`) %>%
  summarise(total_count = sum(Count), .groups = "drop") %>%
  mutate(proportion = total_count / sum(total_count),
         `Q3.16_label` = paste0(`Q3.16_label`, " (", round(proportion * 100, 2), " %)"))
ggplot(q3_16_summary, aes(x = "",y = proportion, fill = `Q3.16_label`)) +
  geom_col(width = 1) +
  coord_polar(theta = "y") +
  labs(title = "Q3.16 Frequency of Checking Inflation Forecasts Summary Pie Chart",
       x = "",
       y = "") +
  theme_minimal() +
  theme(axis.text.x = element_blank())
```

## Q3.17 Source of Inflation Forecasts
Which source do you rely on to obtain inflation forecasts (information about future inflation)?\
Variable: categorical\
Method: convert to list and count + chi-squared test\
**Result: Fail to reject the null hypothesis**
```{r}
q3_17_table <- rawdata_value[, c("Q3.17", "group")]
q3_17_table$Q3.17 <- lapply(q3_17_table$Q3.17, function(x) as.list(as.numeric(strsplit(x, ",")[[1]])))
# count the number of occurrences of each value
q3_17_prop <- q3_17_table %>%
  unnest(Q3.17) %>%
  group_by(group,`Q3.17`) %>%
  summarise(count = n(), .groups = 'drop')
q3_17_prop$Q3.17 <- as.numeric(q3_17_prop$Q3.17)
# create a contingency table
q3_17_contingency <- xtabs(count ~ `Q3.17` + group, data = q3_17_prop)
print(q3_17_contingency)
# Chi-squared test
chisq.test(q3_17_contingency)
```
Plot source of inflation forecasts proportion bar plot across different groups
```{r}
# convert contingency table to data frame
q3_17_prop <- as.data.frame(q3_17_contingency) %>%
  left_join(group_total, by = "group") %>%
  mutate(Proportion = Freq / n_respondents)
# add a labelled column
q3_17_prop <- q3_17_prop %>%
  mutate(Q3.17_label = case_when(
    `Q3.17` == "1" ~ "1-Television, radio or print media",
    `Q3.17` == "2" ~ "2-Social media",
    `Q3.17` == "3" ~ "3-Official websites or data releases",
    `Q3.17` == "4" ~ "4-Content platform",
    `Q3.17` == "5" ~ "5-Actively search on search engines",
    `Q3.17` == "6" ~ "6-Family or friends",
    `Q3.17` == "7" ~ "7-Financial advice websites/forums",
    `Q3.17` == "8" ~ "8-Private banks or economic research institutes",
    `Q3.17` == "9" ~ "9-Other"
  ))
ggplot(q3_17_prop, aes(x = factor(`Q3.17_label`), y = Proportion, fill = group)) +
  geom_col(position = "dodge") +
  labs(
    title = "Q3.17 Source of Inflation Forecasts Propotion Plot across Groups",
    x = "Response",
    y = "Proportion",
    fill = "Group"
  ) +
   scale_fill_brewer(palette = "Set2")+
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
Plot percentage bar chart including all participants
```{r}
q3_17_summary <- q3_17_prop %>%
  group_by(`Q3.17_label`) %>%
  summarise(total_count = sum(Freq), .groups = "drop") %>%
  mutate(proportion = total_count / total_respondents)
ggplot(q3_17_summary, aes(x = factor(Q3.17_label), y = proportion)) +
  geom_col(fill = "steelblue") +
  geom_text(aes(label = paste0(round(proportion * 100, 1), "%")), 
            vjust = -0.3, size = 3.5) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  labs(
    title = "Percentage of Participants Selecting Each Q3.17 Option",
    x = "Response",
    y = "Percentage of Participants"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

## Q3.18 Impact of Inflation Forecasts
To what extent do you feel that inflation forecasts (information about future inflation) impact your personal finances?\
Variable: categorical\
Method: contingency table + chi-squared test\
**Result: Fail to reject the null hypothesis**
```{r}
# Initial Check
summary(as.numeric(rawdata_value$Q3.18))
q3_18_table <- rawdata_value[, c("Q3.18", "group")]
q3_18_contingency <- table(q3_18_table$Q3.18, q3_18_table$group)
print(q3_18_contingency)
# Chi-squared test
chisq.test(q3_18_contingency)
```
Impact of Inflation Forecasts proportion bar plot across different groups
```{r}
q3_18_prop  <- as.data.frame(q3_18_contingency)
# rename columns
names(q3_18_prop) <- c("Q3.18", "Group", "Count")
# add a labelled column
q3_18_prop <- q3_18_prop %>%
  mutate(Q3.18_label = case_when(
    Q3.18 == "1" ~ "1-Not at all",
    Q3.18 == "2" ~ "2-Slightly",
    Q3.18 == "3" ~ "3-Moderately",
    Q3.18 == "4" ~ "4-Very significantly"
  ))
# calculate proportions within each group
q3_18_prop <- q3_18_prop %>%
  group_by(Group) %>%
  mutate(Proportion = Count / sum(Count))
ggplot(q3_18_prop, aes(x = as.factor(`Q3.18_label`), y = Proportion, fill = Group)) + geom_col(position = "dodge") +
  labs(
    title = "Q3.18 Impact of Inflation Forecasts Propotion Plot across Groups",
    x = "Response",
    y = "Proportion"
  ) +
   scale_fill_brewer(palette = "Set2")+
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```
Plot pie chart including all participants
```{r}
q3_18_summary <- q3_18_prop %>%
  group_by(`Q3.18_label`) %>%
  summarise(total_count = sum(Count), .groups = "drop") %>%
  mutate(proportion = total_count / sum(total_count),
         `Q3.18_label` = paste0(`Q3.18_label`, " (", round(proportion * 100, 2), " %)"))
ggplot(q3_18_summary, aes(x = "",y = proportion, fill = `Q3.18_label`)) +
  geom_col(width = 1) +
  coord_polar(theta = "y") +
  labs(title = "Q3.18 Impact of Inflation Forecasts Summary Pie Chart",
       x = "",
       y = "") +
  theme_minimal() +
  theme(axis.text.x = element_blank())
```

## Q3.19 Response to Inflation Forecasts
How much do you adjust or take action in response to inflation forecasts (information about future inflation)?\
Variable: categorical\
Method: contingency table + chi-squared test\
**Result: Fail to reject the null hypothesis**
```{r}
# Initial Check
summary(as.numeric(rawdata_value$Q3.19))
q3_19_table <- rawdata_value[, c("Q3.19", "group")]
q3_19_contingency <- table(q3_19_table$Q3.19, q3_19_table$group)
print(q3_19_contingency)
# Chi-squared test
chisq.test(q3_19_contingency)
```
Response to Inflation Forecasts proportion bar plot across different groups
```{r}
q3_19_prop  <- as.data.frame(q3_19_contingency)
# rename columns
names(q3_19_prop) <- c("Q3.19", "Group", "Count")
# add a labelled column
q3_19_prop <- q3_19_prop %>%
  mutate(Q3.19_label = case_when(
    Q3.19 == "1" ~ "1-Not at all",
    Q3.19 == "2" ~ "2-Rarely",
    Q3.19 == "3" ~ "3-Somewhat actively",
    Q3.19 == "4" ~ "4-Very actively"
  ))
# calculate proportions within each group
q3_19_prop <- q3_19_prop %>%
  group_by(Group) %>%
  mutate(Proportion = Count / sum(Count))
ggplot(q3_19_prop, aes(x = as.factor(`Q3.19_label`), y = Proportion, fill = Group)) + geom_col(position = "dodge") +
  labs(
    title = "Q3.19 Response to Inflation Forecasts Propotion Plot across Groups",
    x = "Response",
    y = "Proportion"
  ) +
   scale_fill_brewer(palette = "Set2")+
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
Plot pie chart including all participants
```{r}
q3_19_summary <- q3_19_prop %>%
  group_by(`Q3.19_label`) %>%
  summarise(total_count = sum(Count), .groups = "drop") %>%
  mutate(proportion = total_count / sum(total_count),
         `Q3.19_graph_label` = paste0(`Q3.19_label`, " (", round(proportion * 100, 2), " %)"))
ggplot(q3_19_summary, aes(x = "",y = proportion, fill = `Q3.19_graph_label`)) +
  geom_col(width = 1) +
  coord_polar(theta = "y") +
  labs(title = "Q3.19 Response to Inflation Forecasts Summary Pie Chart",
       x = "",
       y = "") +
  theme_minimal() +
  theme(axis.text.x = element_blank())
```



## Comparison of current inflation and inflation forecast
Frequency
```{r}
q3_12_long <- q3_12_prop %>%
group_by(`Q3.12_label`) %>%
  rename(choice = `Q3.12_label`) %>%
  summarise(total_count = sum(Count), .groups = "drop") %>%
  mutate(proportion = total_count / sum(total_count),
         question = "Q3.12 Current Inflation")

q3_16_long <- q3_16_prop %>%
  group_by(`Q3.16_label`) %>%
  rename(choice = `Q3.16_label`) %>%
  summarise(total_count = sum(Count), .groups = "drop") %>%
  mutate(proportion = total_count / sum(total_count),
         question = "Q3.16 Infaltion Forecasts")

# bind them together
q3_frequency <- bind_rows(q3_12_long, q3_16_long)

ggplot(q3_frequency, aes(x = choice, y = proportion, fill = question)) +
  geom_col(position = position_dodge(width = 0.8), width = 0.7) +
  geom_text(aes(label = scales::percent(proportion, accuracy = 0.1)), 
            position = position_dodge(width = 0.8), vjust = -0.5) +
  scale_y_continuous(
    expand = expansion(mult = c(0, 0.1)) 
  ) +
  labs(
    title = "(Frequency) Comparison of Q3.12 vs Q3.16 Response Proportions",
    x     = "Response category",
    y     = "Proportion",
    fill  = "Question"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1)
  )
```
Chi-squared Testing
```{r}
q3_12_t <- q3_12_table %>%
  rename(choice = `Q3.12`) %>%
  mutate(question = "Q3.12")
q3_16_t <- q3_16_table %>%
  rename(choice = `Q3.16`) %>%
  mutate(question = "Q3.16")
# bind them together
q3_frequency_t <- bind_rows(q3_12_t, q3_16_t)
q3_frequency_table <- table(q3_frequency_t$choice, q3_frequency_t$question)
print(q3_frequency_table)
chisq.test(q3_frequency_table)

chisq_result <- chisq.test(q3_frequency_table)
std_resid <- chisq_result$stdres
print(std_resid)

# cramerV(q3_frequency_table)

```

Source
```{r}
q3_13_long <- q3_13_summary %>%
  rename(choice = `Q3.13_label`) %>%
  mutate(question = "Q3.13 Current Inflation")
q3_17_long <- q3_17_summary %>%
  rename(choice = `Q3.17_label`) %>%
  mutate(question = "Q3.17 Infaltion Forecasts")
# bind them together
q3_source <- bind_rows(q3_13_long, q3_17_long)
# plot
ggplot(q3_source, aes(x = choice, y = proportion, fill = question)) +
  geom_col(position = position_dodge(width = 0.8), width = 0.7) +
  geom_text(aes(label = scales::percent(proportion, accuracy = 0.1)), 
            position = position_dodge(width = 0.8), vjust = -0.5,size = 2) +
  labs(
    title = "(Source) Comparison of Q3.13 vs Q3.17 Response Proportions",
    x     = "Response category",
    y     = "Proportion",
    fill  = "Question"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1)
  )

```
Impact
```{r}
q3_14_long <- q3_14_prop %>%
group_by(`Q3.14_label`) %>%
  rename(choice = `Q3.14_label`) %>%
  summarise(total_count = sum(Count), .groups = "drop") %>%
  mutate(proportion = total_count / sum(total_count),
         question = "Q3.14 Current Inflation")

q3_18_long <- q3_18_prop %>%
  group_by(`Q3.18_label`) %>%
  rename(choice = `Q3.18_label`) %>%
  summarise(total_count = sum(Count), .groups = "drop") %>%
  mutate(proportion = total_count / sum(total_count),
         question = "Q3.18 Infaltion Forecasts")
# bind them together
q3_impact <- bind_rows(q3_14_long, q3_18_long)

ggplot(q3_impact, aes(x = choice, y = proportion, fill = question)) +
  # facet_wrap(~ question) +
  geom_col(position = position_dodge(width = 0.8), width = 0.7) +
  geom_text(aes(label = scales::percent(proportion, accuracy = 0.1)), 
        position = position_dodge(width = 0.8), vjust = -0.5,size =3) +
  scale_y_continuous(
    expand = expansion(mult = c(0, 0.1)) 
  ) +
  labs(
    title = "(Impact) Comparison of Q3.14 vs Q3.18 Response Proportions",
    x     = "Response category",
    y     = "Proportion",
    fill  = "Question"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1)
  )
```
Response
```{r}
q3_15_long <- q3_15_prop %>%
group_by(`Q3.15_label`) %>%
  rename(choice = `Q3.15_label`) %>%
  summarise(total_count = sum(Count), .groups = "drop") %>%
  mutate(proportion = total_count / sum(total_count),
         question = "Q3.15 Current Inflation")
q3_19_long <- q3_19_prop %>%
  group_by(`Q3.19_label`) %>%
  rename(choice = `Q3.19_label`) %>%
  summarise(total_count = sum(Count), .groups = "drop") %>%
  mutate(proportion = total_count / sum(total_count),
         question = "Q3.19 Infaltion Forecasts")
# bind them together
q3_response <- bind_rows(q3_15_long, q3_19_long)
ggplot(q3_response, aes(x = choice, y = proportion, fill = question)) +
  geom_col(position = position_dodge(width = 0.8), width = 0.7) +
  geom_text(aes(label = scales::percent(proportion, accuracy = 0.1)), 
            position = position_dodge(width = 0.8), vjust = -0.5, size =3) +
  scale_y_continuous(
    expand = expansion(mult = c(0, 0.1)) 
  ) +
  labs(
    title = "(Response) Comparison of Q3.15 vs Q3.19 Response Proportions",
    x     = "Response category",
    y     = "Proportion",
    fill  = "Question"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1)
  )
```

# Actual Survey Analysis <a name="actual-survey-analysis"></a>

## Qxx.2 Graph Familarity
Have you ever been communicated this type of information before?\
Variable: categorical\
Method: Contingency Table + Chi-squared test\
*recode to yes and no*\
**Result: We can reject the null hypothesis, meaning people are more or less familiar with certain type of visualisations.**
```{r}
# combine data from different groups
survey_q2 <- data.frame()
survey_q2_list <- list("Q4.2","Q6.2", "Q8.2", "Q10.2", "Q12.2")

for (i in seq_along(group_list)) {
  df <- group_list[[i]]
  col <- survey_q2_list[[i]]
  temp_table <- df[, c(col, "group")]
  names(temp_table) <- c("q2_value", "group")
  survey_q2 <- rbind(survey_q2, temp_table)
}

# recode the category
survey_q2 <- survey_q2 %>%
  mutate(q2_recode = case_when(
    q2_value %in% c("1", "2") ~ "N",
    q2_value %in% c("3", "4") ~ "Y"
  ))

survey_q2_contingency <- table(survey_q2$q2_recode, survey_q2$group)
# print the contingency table
print(survey_q2_contingency)
# Chi-squared test
chisq.test(survey_q2_contingency)

# chisq_result <- chisq.test(survey_q2_contingency)
# chisq_result$stdres  
# chisq_result$expected #(If many values are < 5, your Chi-squared test may be less reliable.)
# Post-hoc test for N --> no single pairwise difference is strong
# pairwise.prop.test(
#   x = survey_q2_contingency["N", ],
#   n = colSums(survey_q2_contingency),
#   p.adjust.method = "holm"
# )

```

Summary Table of proportion of yes and no

```{r}
yes_per <- survey_q2_contingency[2,]
no_per <- survey_q2_contingency[1,]
familarity_group_total <- colSums(survey_q2_contingency)
yes_prop <- yes_per/familarity_group_total
no_prop <- no_per/familarity_group_total
# convert to data frame
survey_q2_summary <-data.frame(yes_prop, no_prop)

```

Plot the graph

```{r}
ggplot(survey_q2, aes(x = q2_recode, fill = group)) +
  geom_bar(position = "dodge") +
  labs(title = "Have you ever been communicated this type of information before?",
       x = "Response",
       y = "Count") +
  scale_fill_brewer(palette = "Set2") +
  theme_minimal()
```

## Qxx.3 Prior Expectation
Does the inflation forecast information provided align with your expectations?\
Variable: categorical\
Method: Contingency Table + Chi-squared test\
**Result: Fail to reject the null hypothesis**
```{r}
# combine data from different groups
survey_q3 <- data.frame()
survey_q3_list <- list("Q4.3","Q6.3", "Q8.3", "Q10.3", "Q12.3")
for (i in seq_along(group_list)) {
  df <- group_list[[i]]
  col <- survey_q3_list[[i]]
  temp_table <- df[, c(col, "group")]
  names(temp_table) <- c("q3_value", "group")
  survey_q3 <- rbind(survey_q3, temp_table)
}

# Initial Check
summary(as.numeric(survey_q3$q3_value))
```
Test the differences between groups
```{r}
survey_q3_contingency <- table(survey_q3$q3_value, survey_q3$group)
# print the contingency table
print(survey_q3_contingency)
# Chi-squared test
chisq.test(survey_q3_contingency)
```
Plot prior expectation proportion bar plot across different groups
```{r}
survey_q3_prop  <- as.data.frame(survey_q3_contingency)
# rename columns
names(survey_q3_prop) <- c("Q3.3", "Group", "Count")
# add a labelled column
survey_q3_prop <- survey_q3_prop %>%
  mutate(Q3.3_label = case_when(
    Q3.3 == "1" ~ "1-Strongly aligns",
    Q3.3 == "2" ~ "2-Somewhat aligns",
    Q3.3 == "3" ~ "3-Neutral",
    Q3.3 == "4" ~ "4-Somewhat does not align",
    Q3.3 == "5" ~ "5-Does not align at all",
  ))
# calculate proportions within each group
survey_q3_prop <- survey_q3_prop %>%
  group_by(Group) %>%
  mutate(Proportion = Count / sum(Count))
ggplot(survey_q3_prop, aes(x = as.factor(`Q3.3_label`), y = Proportion, fill = Group)) + geom_col(position = "dodge") +
  labs(
    title = "Q3.3 Prior Expectation Propotion Plot across Groups",
    x = "Response",
    y = "Proportion"
  ) +
   scale_fill_brewer(palette = "Set2")+
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
Plot pie chart including all participants
```{r}
survey_q3_summary <- survey_q3_prop %>%
  group_by(`Q3.3_label`) %>%
  summarise(total_count = sum(Count), .groups = "drop") %>%
  mutate(proportion = total_count / sum(total_count),
         `Q3.3_graph_label` = paste0(`Q3.3_label`, " (", round(proportion * 100, 2), " %)"))
ggplot(survey_q3_summary, aes(x = "",y = proportion, fill = `Q3.3_graph_label`)) +
  geom_col(width = 1) +
  coord_polar(theta = "y") +
  labs(title = "Q3.3 Prior Expectation Summary Pie Chart",
       x = "",
       y = "") +
  theme_minimal() +
  theme(axis.text.x = element_blank())
```
## Qxx.4 Confliction with Prior Expectation
How does the inflation forecast conflict with your expectations?\
Variable: categorical\
Method: calculate total number of people who think the forecast is not aligned with their expectation\
**Result: Among people who think the forecast is not aligned with their expectation, 90% percent of respondents thinks the forecast is lower than what they expected.**
```{r}
# Check the number of people answered this question
n_not_align <- sum(survey_q3_summary$total_count[4:5])
# Combine data from different groups
survey_q4 <- data.frame()
survey_q4_list <- list("Q4.4","Q6.4", "Q8.4", "Q10.4", "Q12.4")
for (i in seq_along(group_list)) {
  df <- group_list[[i]]
  col <- survey_q4_list[[i]]
  temp_table <- df[, c(col, "group")]
  names(temp_table) <- c("q4_value", "group")
  survey_q4 <- rbind(survey_q4, temp_table)
}
survey_q4 <- survey_q4[!is.na(survey_q4$q4_value), ]
survey_q4_contingency <- table(survey_q4$q4_value, survey_q4$group)
# print the contingency table
print(survey_q4_contingency)

```
Plot confliction with prior expectation proportion bar plot across different groups
```{r}
survey_q4_prop  <- as.data.frame(survey_q4_contingency)
# rename columns
names(survey_q4_prop) <- c("Q4.4", "Group", "Count")
# add a labelled column
survey_q4_prop <- survey_q4_prop %>%
  mutate(Q4.4_label = case_when(
    Q4.4 == "1" ~ "1-Higher than what I expected",
    Q4.4 == "2" ~ "2-Lower than what I expected"
  ))
# calculate proportions within each group
survey_q4_prop <- survey_q4_prop %>%
  group_by(Group) %>%
  mutate(Proportion = Count / sum(Count))
ggplot(survey_q4_prop, aes(x = as.factor(`Q4.4_label`), y = Proportion, fill = Group)) + geom_col(position = "dodge") +
  labs(
    title = "Q4.4 Confliction with Prior Expectation Propotion Plot across Groups",
    x = "Response",
    y = "Proportion"
  ) +
   scale_fill_brewer(palette = "Set2")+
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
Plot pie chart including all participants
```{r}
survey_q4_summary <- survey_q4_prop %>%
  group_by(`Q4.4_label`) %>%
  summarise(total_count = sum(Count), .groups = "drop") %>%
  mutate(proportion = total_count / sum(total_count),
         `Q4.4_graph_label` = paste0(`Q4.4_label`, " (", round(proportion * 100, 2), " %)"))
ggplot(survey_q4_summary, aes(x = "",y = proportion, fill = `Q4.4_graph_label`)) +
  geom_col(width = 1) +
  coord_polar(theta = "y") +
  labs(title = "Q4.4 Confliction with Prior Expectation Summary Pie Chart",
       x = "",
       y = "") +
  theme_minimal() +
  theme(axis.text.x = element_blank())
```
## Qxx.6 Probability of exactly 2.6%
what do you think is the probability of inflation being exactly 2.6%?\
Definitive Correct Answer\
*descending order*\
Variable: categorical\
Method: contingency table & proportion test\
**Result: There is no statistical difference in terms of correctly answering the probability of inflation being exactly 2.6%.**
```{r}
# combine data from different groups
survey_q6 <- data.frame()
survey_q6_list <- list("Q4.6","Q6.6", "Q8.6", "Q10.6", "Q12.6")
for (i in seq_along(group_list)) {
  df <- group_list[[i]]
  col <- survey_q6_list[[i]]
  temp_table <- df[, c(col, "group")]
  names(temp_table) <- c("q6_value", "group")
  survey_q6 <- rbind(survey_q6, temp_table)
}
survey_q6$q6_value <- as.numeric(survey_q6$q6_value)

survey_q6_contingency <- table(survey_q6$q6_value, survey_q6$group)
print(survey_q6_contingency)


# whether one proportion differs across groups
less_than_1_per <- survey_q6_contingency[7,]
survey_q6_group_total <- colSums(survey_q6_contingency)
prop.test(less_than_1_per, survey_q6_group_total)

```
Plot probability of exactly 2.6% proportion bar plot across different groups
```{r}
survey_q6_prop  <- as.data.frame(survey_q6_contingency)
# rename columns
names(survey_q6_prop) <- c("Qxx.6", "Group", "Count")
# add a labelled column
survey_q6_prop <- survey_q6_prop %>%
  mutate(Qxx.6_label = case_when(
    Qxx.6 == "1" ~ "1->99%",
    Qxx.6 == "2" ~ "2-around 80%",
    Qxx.6 == "3" ~ "3-around 60%",
    Qxx.6 == "4" ~ "4-around 50%",
    Qxx.6 == "5" ~ "5-around 30%",
    Qxx.6 == "6" ~ "6-around 20%",
    Qxx.6 == "7" ~ "7-<1%"
  ))
# calculate proportions within each group
survey_q6_prop <- survey_q6_prop %>%
  group_by(Group) %>%
  mutate(Proportion = Count / sum(Count))
ggplot(survey_q6_prop, aes(x = as.factor(`Qxx.6_label`), y = Proportion, fill = Group)) + geom_col(position = "dodge") +
  # facet_wrap(~Group)+
  labs(
    title = "Qxx.6 Probability of Being Exactly 2.6% Propotion Plot across Groups",
    x = "Response",
    y = "Proportion"
  ) +
   scale_fill_brewer(palette = "Set2")+
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
Plot the histogram including all participants
```{r}
# histogram including all participants
ggplot(survey_q6, aes(x = q6_value)) +
  geom_histogram(binwidth = 1, fill = "steelblue", color = "white") +
  labs(title = "Qxx.6 Probability of exactly 2.6% Histogram",
       x = "Response",
       y = "Count") +
  scale_x_continuous(breaks = seq(0, max(survey_q6$q6_value, na.rm = TRUE), by = 1)) +
  theme_minimal()
```


Plot pie chart including all participants
```{r}
survey_q6_summary <- survey_q6_prop %>%
  group_by(`Qxx.6_label`) %>%
  summarise(total_count = sum(Count), .groups = "drop") %>%
  mutate(proportion = total_count / sum(total_count),
         `Q6.6_graph_label` = paste0(`Qxx.6_label`, " (", round(proportion * 100, 2), " %)"))
ggplot(survey_q6_summary, aes(x = "",y = proportion, fill = `Q6.6_graph_label`)) +
  geom_col(width = 1) +
  coord_polar(theta = "y") +
  labs(title = "Qxx.6 Probability of exactly 2.6% Summary Pie Chart",
       x = "",
       y = "") +
  theme_minimal() +
  theme(axis.text.x = element_blank())
```

## ! Qxx.7 Probability of between 1.9% and 3.3%
what do you think is the probability of inflation being between 1.9% and 3.3%?\
Definitive Correct Answer\
*descending order*\
Method: contingency table & proportion test\
**Result: There is statistical difference in control group in terms of the proportion of the correct answer of how people think the probability of inflation being between 1.9% and 3.3% is. **\
```{r}
# combine data from different groups
survey_q7 <- data.frame()
survey_q7_list <- list("Q4.7","Q6.7", "Q8.7", "Q10.7", "Q12.7")
for (i in seq_along(group_list)) {
  df <- group_list[[i]]
  col <- survey_q7_list[[i]]
  temp_table <- df[, c(col, "group")]
  names(temp_table) <- c("q7_value", "group")
  survey_q7 <- rbind(survey_q7, temp_table)
}
survey_q7$q7_value <- as.numeric(survey_q7$q7_value)
```

Test the proportion of correct answer
```{r}
survey_q7_contingency <- table(survey_q7$q7_value, survey_q7$group)
# print the contingency table
print(survey_q7_contingency)
# correct answer
survey_q7_correct <- survey_q7_contingency[5,]
survey_q7_group_total <- colSums(survey_q7_contingency)
prop.test(survey_q7_correct, survey_q7_group_total)
# pairwise proportion test
pairwise.prop.test(
  x = survey_q7_contingency[5, ],
  n = colSums(survey_q7_contingency),
  p.adjust.method = "bonferroni" # or "holm", "BH"
)
```


Plot probability of between 1.9% and 3.3% proportion bar plot across different groups
```{r}
survey_q7_prop  <- as.data.frame(survey_q7_contingency)
# rename columns
names(survey_q7_prop) <- c("Qxx.7", "Group", "Count")
# add a labelled column
survey_q7_prop <- survey_q7_prop %>%
  mutate(Qxx.7_label = case_when(
    Qxx.7 == "1" ~ "1->99%",
    Qxx.7 == "2" ~ "2-around 80%",
    Qxx.7 == "3" ~ "3-around 60%",
    Qxx.7 == "4" ~ "4-around 50%",
    Qxx.7 == "5" ~ "5-around 30%",
    Qxx.7 == "6" ~ "6-around 20%",
    Qxx.7 == "7" ~ "7-<1%"
  ))
# calculate proportions within each group
survey_q7_prop <- survey_q7_prop %>%
  group_by(Group) %>%
  mutate(Proportion = Count / sum(Count))
ggplot(survey_q7_prop, aes(x = as.factor(`Qxx.7_label`), y = Proportion, fill = Group)) + geom_col(position = "dodge") +
  # facet_wrap(~Group)+
  labs(
    title = "Qxx.7 Probability of between 1.9% and 3.3% Propotion Plot across Groups",
    x = "Response",
    y = "Proportion"
  ) +
   scale_fill_brewer(palette = "Set2")+
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
Plot the histogram including all participants
```{r}
# histogram including all participants
ggplot(survey_q7, aes(x = q7_value)) +
  geom_histogram(binwidth = 1, fill = "steelblue", color = "white") +
  geom_text(     stat = "bin",
    aes(
      label = after_stat(
        ifelse(
          count == 0,                     
          "",                             
          scales::percent(count / total_respondents, accuracy = 0.1)
        )
      )
    ), vjust = -0.5, size = 3) +
  # facet_wrap(~ group) +
  labs(title = "Qxx.7 Probability of between 1.9% and 3.3% Histogram",
       x = "Qxx.7",
       y = "Count") +
  scale_x_continuous(breaks = seq(0, max(survey_q7$q7_value, na.rm = TRUE), by = 1)) +
  theme_minimal()
```


## Qxx.8 Probability of between 3.3% and 5.6%
what do you think is the probability of inflation being between 3.3% and 5.6%?\
Definitive Correct Answer\
*descending order*\
Method: contingency table & proportion test\
**Result: The control group and the error bar group has shown statistical difference.**\
```{r}
# combine data from different groups
survey_q8 <- data.frame()
survey_q8_list <- list("Q4.8","Q6.8", "Q8.8", "Q10.8", "Q12.8")
for (i in seq_along(group_list)) {
  df <- group_list[[i]]
  col <- survey_q8_list[[i]]
  temp_table <- df[, c(col, "group")]
  names(temp_table) <- c("q8_value", "group")
  survey_q8 <- rbind(survey_q8, temp_table)
}
survey_q8$q8_value <- as.numeric(survey_q8$q8_value)

```

contingency table
```{r}
survey_q8_contingency <- table(survey_q8$q8_value, survey_q8$group)
# print the contingency table
print(survey_q8_contingency)
# correct answer
survey_q8_correct <- survey_q8_contingency[5,]
survey_q8_group_total <- colSums(survey_q8_contingency)
prop.test(survey_q8_correct, survey_q8_group_total)
# pairwise proportion test
pairwise.prop.test(
  x = survey_q8_contingency[5, ],
  n = colSums(survey_q8_contingency),
  p.adjust.method = "bonferroni" # or "holm", "BH"
)


```
Plot probability of between 3.3% and 5.6% proportion bar plot across different groups
```{r}
survey_q8_prop  <- as.data.frame(survey_q8_contingency)
# rename columns
names(survey_q8_prop) <- c("Qxx.8", "Group", "Count")
# add a labelled column
survey_q8_prop <- survey_q8_prop %>%
  mutate(Qxx.8_label = case_when(
    Qxx.8 == "1" ~ "1->99%",
    Qxx.8 == "2" ~ "2-around 80%",
    Qxx.8 == "3" ~ "3-around 60%",
    Qxx.8 == "4" ~ "4-around 50%",
    Qxx.8 == "5" ~ "5-around 30%",
    Qxx.8 == "6" ~ "6-around 20%",
    Qxx.8 == "7" ~ "7-<1%"
  ))
# calculate proportions within each group
survey_q8_prop <- survey_q8_prop %>%
  group_by(Group) %>%
  mutate(Proportion = Count / sum(Count))
ggplot(survey_q8_prop, aes(x = as.factor(`Qxx.8_label`), y = Proportion, fill = Group)) + geom_col(position = "dodge") +
  # facet_wrap(~Group)+
  labs(
    title = "Qxx.8 Probability of between 3.3% and 5.6% Propotion Plot across Groups",
    x = "Response",
    y = "Proportion"
  ) +
   scale_fill_brewer(palette = "Set2")+
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
Plot the histogram including all participants
```{r}
# histogram including all participants
ggplot(survey_q8, aes(x = q8_value)) +
  geom_histogram(binwidth = 1, fill = "steelblue", color = "white") +
  # facet_wrap(~ group) +
  labs(title = "Qxx.8 Probability of between 3.3% and 5.6% Histogram",
       x = "Qxx.8",
       y = "Count") +
  scale_x_continuous(breaks = seq(0, max(survey_q8$q8_value, na.rm = TRUE), by = 1)) +
  theme_minimal()
```
## ! Qxx.10 Probability of ending outside the range
Based on the inflation forecast provided, what do you think is the probability of inflation ending up outside of  the range from -0.4% to 5.6%?\
Definitive Correct Answer (varied between group)\
*descending order*\
Variable: categorical\
Method: calculate the proportion for each group + proportion test\
**Result: Control group perform significant worse than other groups.**\
```{r}
survey_q10 <- data.frame(
  group   = character(0),
  correct = integer(0),
  total   = integer(0),
  prop    = numeric(0)
)
survey_q10_list <- list("Q4.10","Q6.10", "Q8.10", "Q10.10", "Q12.10")
survey_q10_correct <-c(8,12,14,14,14) # 10%, 40%. 10%, 10%, 10%

for (i in seq_along(group_list)) {
  df <- group_list[[i]]
  col <- survey_q10_list[[i]]
  q10_correct <- survey_q10_correct[i]
  
  # count total number of people in each group
  total_count <- nrow(df)
  # count number of people who answered correctly
  correct_count <- sum(df[, col] == q10_correct, na.rm = TRUE)
  # compute the proportion
  prop <- correct_count / total_count
  # capture the group name
  grp_label <- names(group_list[i])  
  # row-bind into survey_q10
  survey_q10 <- rbind(survey_q10, data.frame(
    group = grp_label,
    correct = correct_count,
    total = total_count,
    prop = prop))
}

# proportion test --> There is significant difference
prop.test(x = survey_q10$correct,
          n = survey_q10$total)
# pairwise proportion test
pairwise.prop.test(
  x = setNames(survey_q10$correct, survey_q10$group),
  n = setNames(survey_q10$total,   survey_q10$group),
  p.adjust.method = "bonferroni" # or "holm", "BH"
)
```

```{r}

ggplot(survey_q10, aes(x = group, y = prop)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  geom_text(aes(label = scales::percent(prop, accuracy = 1)), vjust = -0.5) +
  labs(title = "Qxx.10 Probability of ending outside the range correct answer rate",
       x = "Group",
       y = "Proportion") +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_minimal()
```
Plot distribution for each individual group (change the group and question number manually)
```{r}
ggplot(bell_curve, aes(x = as.numeric(as.character(Q12.10)))) +
  geom_histogram(binwidth = 1, fill = "steelblue", color = "white") +
  scale_y_continuous(
    limits = c(0, 50),        # force y from 0 up to 60
    breaks = seq(0, 50, by=10) # ticks at 0, 10, 20, …, 60
  ) +
  geom_text(aes(label = ..count..), stat = "count", vjust = -0.5) +
  labs(
    title = "Controlled Group: Distribution of Q4.10 Responses",
    x     = "Q4.10 (numeric)",
    y     = "Count"
  ) +
  theme_minimal()
```
## Qxx.11 Probability of higher than 6%
Based on the inflation forecast provided, what do you think is the probability of inflation ending up higher than 6%?\
Definitive Correct Answer - 3\
variable: categorical\
Method: contingency table & proportion test\
**Result: The bell curve and the control group has shown significant difference. The majority people think the probability is extremely low (less than 1%).**\
```{r}
# combine data from different groups
survey_q11 <- data.frame()
survey_q11_list <- list("Q4.11","Q6.11", "Q8.11", "Q10.11", "Q12.11")
for (i in seq_along(group_list)) {
  df <- group_list[[i]]
  col <- survey_q11_list[[i]]
  temp_table <- df[, c(col, "group")]
  names(temp_table) <- c("q11_value", "group")
  survey_q11 <- rbind(survey_q11, temp_table)
}
survey_q11$q11_value <- as.numeric(survey_q11$q11_value)

```

Test the proportion of correct answer
```{r}
survey_q11_contingency <- table(survey_q11$q11_value, survey_q11$group)
# print the contingency table
print(survey_q11_contingency)
survey_q11_correct <- survey_q11_contingency[3,]
survey_q11_group_total <- colSums(survey_q11_contingency)
prop.test(survey_q11_correct, survey_q11_group_total)

```
Post-hoc test
```{r}
pairwise.prop.test(
  x = survey_q11_contingency[3, ],
  n = colSums(survey_q11_contingency),
  p.adjust.method = "bonferroni" # or "holm", "BH"
)
```
Plot probability of higher than 6% proportion bar plot across different groups
```{r}
survey_q11_prop  <- as.data.frame(survey_q11_contingency)
# rename columns
names(survey_q11_prop) <- c("Qxx.11", "Group", "Count")
# add a labelled column
survey_q11_prop <- survey_q11_prop %>%
  mutate(Qxx.11_label = case_when(
    Qxx.11 == "1" ~ "1-More than 20%",
    Qxx.11 == "2" ~ "3-5-10%",
    Qxx.11 == "3" ~ "4-1-5%",
    Qxx.11 == "4" ~ "5-Less than 1%",
    Qxx.11 == "5" ~ "2-10-20%"
  ))
# calculate proportions within each group
survey_q11_prop <- survey_q11_prop %>%
  group_by(Group) %>%
  mutate(Proportion = Count / sum(Count))
ggplot(survey_q11_prop, aes(x = as.factor(`Qxx.11_label`), y = Proportion, fill = Group)) + geom_col(position = "dodge") +
  # facet_wrap(~Group)+
  labs(
    title = "Qxx.11 Probability of higher than 6% Propotion Plot across Groups",
    x = "Response",
    y = "Proportion"
  ) +
   scale_fill_brewer(palette = "Set2")+
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
Plot the histogram including all participants
```{r}
# force order for graph
survey_q11 <- survey_q11 %>%
  mutate(
    q11_value_re = factor(
      q11_value,
      levels = c(1, 5, 2, 3, 4)
    )
  )
# histogram including all participants
ggplot(survey_q11, aes(x = q11_value_re)) +
  geom_bar(fill = "steelblue", color = "white") +
  labs(
    title = "Qxx.11 Responses (forced 1-5-2-3-4 order)",
    x     = "Qxx.11",
    y     = "Count"
  ) +
  theme_minimal()
```
## Qxx.12 Probability of higher than 3% 
Based on the inflation forecast provided, what do you think is the probability of inflation ending up higher than 3%?\
Definitive Correct Answer - 1\
variable: categorical\
Method: contingency table & proportion test\
**Result: There is no statistical difference and the majority people didn't get the answer right.**
```{r}
# combine data from different groups
survey_q12 <- data.frame()
survey_q12_list <- list("Q4.12","Q6.12", "Q8.12", "Q10.12", "Q12.12")
for (i in seq_along(group_list)) {
  df <- group_list[[i]]
  col <- survey_q12_list[[i]]
  temp_table <- df[, c(col, "group")]
  names(temp_table) <- c("q12_value", "group")
  survey_q12 <- rbind(survey_q12, temp_table)
}
survey_q12$q12_value <- as.numeric(survey_q12$q12_value)

```

Test the proportion of correct answer
```{r}
survey_q12_contingency <- table(survey_q12$q12_value, survey_q12$group)
# print the contingency table
print(survey_q12_contingency)

survey_q12_correct <- survey_q12_contingency[2,]
survey_q12_group_total <- colSums(survey_q12_contingency)
prop.test(survey_q12_correct, survey_q12_group_total)
```
Plot probability of higher than 3% proportion bar plot across different groups
```{r}
survey_q12_prop  <- as.data.frame(survey_q12_contingency)
# rename columns
names(survey_q12_prop) <- c("Qxx.12", "Group", "Count")
# add a labelled column
survey_q12_prop <- survey_q12_prop %>%
  mutate(Qxx.12_label = case_when(
    Qxx.12 == "1" ~ "1-More than 60%",
    Qxx.12 == "2" ~ "3-40-50%",
    Qxx.12 == "3" ~ "4-30-40%",
    Qxx.12 == "4" ~ "5-Less than 30%",
    Qxx.12 == "5" ~ "2-50-60%"
  ))
# calculate proportions within each group
survey_q12_prop <- survey_q12_prop %>%
  group_by(Group) %>%
  mutate(Proportion = Count / sum(Count))
ggplot(survey_q12_prop, aes(x = as.factor(`Qxx.12_label`), y = Proportion, fill = Group)) + geom_col(position = "dodge") +
  # facet_wrap(~Group)+
  labs(
    title = "Qxx.12 Probability of higher than 3% Propotion Plot across Groups",
    x = "Response",
    y = "Proportion"
  ) +
   scale_fill_brewer(palette = "Set2")+
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
Plot the histogram including all participants
```{r}
# force order for graph
survey_q12 <- survey_q12 %>%
  mutate(
    q12_value_re = factor(
      q12_value,
      levels = c(1, 5, 2, 3, 4)
    )
  )
# histogram including all participants
ggplot(survey_q12, aes(x = q12_value_re)) +
  geom_bar(fill = "steelblue", color = "white") +
  labs(
    title = "Qxx.12 Responses (forced 1-5-2-3-4 order)",
    x     = "Qxx.12",
    y     = "Count"
  ) +
  theme_minimal()
```

## ! Qxx.14 Probability of higher than 2% target
To keep inflation low and stable, Government sets an inflation target of 2%.  Based on the inflation forecast provided, what do you think is the probability of inflation exceeding 2%?\
Definitive Correct Answer - 3\
variable: categorical\
Method: contingency table & proportion test\
**Result: Control group is significant different from error Bar group and bell curve group; Error bar group has shown statistical difference compared to fan chart slice. 44% of total respondents can understand the probability of inflation being higher than 6% correctly.**
```{r}
# combine data from different groups
survey_q14 <- data.frame()
survey_q14_list <- list("Q4.14","Q6.14", "Q8.14", "Q10.14", "Q12.14")
for (i in seq_along(group_list)) {
  df <- group_list[[i]]
  col <- survey_q14_list[[i]]
  temp_table <- df[, c(col, "group")]
  names(temp_table) <- c("q14_value", "group")
  survey_q14 <- rbind(survey_q14, temp_table)
}
survey_q14$q14_value <- as.numeric(survey_q14$q14_value)
```
Test the proportion of correct answer
```{r}
survey_q14_contingency <- table(survey_q14$q14_value, survey_q14$group)
# print the contingency table
print(survey_q14_contingency)

survey_q14_correct <- survey_q14_contingency[3,]
survey_q14_group_total <- colSums(survey_q14_contingency)
prop.test(survey_q14_correct, survey_q14_group_total)
```
Pairwise proportion test
```{r}
pairwise.prop.test(
  x = survey_q14_contingency[3, ],
  n = colSums(survey_q14_contingency),
  p.adjust.method = "bonferroni" # or "holm", "BH"
)
```
Plot probability of higher than 2% target proportion bar plot across different groups
```{r}
survey_q14_prop  <- as.data.frame(survey_q14_contingency)
# rename columns
names(survey_q14_prop) <- c("Qxx.14", "Group", "Count")
# add a labelled column
survey_q14_prop <- survey_q14_prop %>%
  mutate(Qxx.14_label = case_when(
    Qxx.14 == "1" ~ "1->99%",
    Qxx.14 == "2" ~ "2-around 80%",
    Qxx.14 == "3" ~ "3-around 60%",
    Qxx.14 == "4" ~ "4-around 50%",
    Qxx.14 == "5" ~ "5-around 30%",
    Qxx.14 == "6" ~ "6-around 20%",
    Qxx.14 == "7" ~ "7-<1%"
  ))
# calculate proportions within each group
survey_q14_prop <- survey_q14_prop %>%
  group_by(Group) %>%
  mutate(Proportion = Count / sum(Count))

ggplot(survey_q14_prop, aes(x = as.factor(`Qxx.14_label`), y = Proportion, fill = Group)) + geom_col(position = "dodge") +
  # facet_wrap(~Group)+
  labs(
    title = "Qxx.14 Probability of higher than 2% target Propotion Plot across Groups",
    x = "Response",
    y = "Proportion"
  ) +
   scale_fill_brewer(palette = "Set2")+
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
Plot the histogram including all participants
```{r}
# histogram including all participants
ggplot(survey_q14, aes(x = q14_value)) +
  geom_histogram(binwidth = 1, fill = "steelblue", color = "white") +
  # facet_wrap(~ group) +
  labs(title = "Qxx.14 Probability of higher than 2% target Histogram",
       x = "Qxx.14",
       y = "Count") +
  scale_x_continuous(breaks = seq(0, max(survey_q14$q14_value, na.rm = TRUE), by = 1)) +
  theme_minimal()
```

## Qxx.15 Deviation from central estimate
Based on the inflation forecast provided, do you think there is a higher risk of inflation in 2026Q2 exceeding the central estimate or of being less than this central estimate?\
Definitive Correct Answer - 3\
variable: categorical\
Method: contingency table & proportion test\
**Result: The control group shows significant difference compared to the shaded bar group in terms of the correctly choosing understanding the risk is equal. Among all participants, only around 8% respondents think there is downside risk. The largest proportion (48%) of participants believe there is upside risk. **
```{r}
# combine data from different groups
survey_q15 <- data.frame()
survey_q15_list <- list("Q4.15","Q6.15", "Q8.15", "Q10.15", "Q12.15")
for (i in seq_along(group_list)) {
  df <- group_list[[i]]
  col <- survey_q15_list[[i]]
  temp_table <- df[, c(col, "group")]
  names(temp_table) <- c("q15_value", "group")
  survey_q15 <- rbind(survey_q15, temp_table)
}
survey_q15$q15_value <- as.numeric(survey_q15$q15_value)
```

Contingency table
```{r}
survey_q15_contingency <- table(survey_q15$q15_value, survey_q15$group)
# print the contingency table
print(survey_q15_contingency)
# chi-squared test
chisq_result <- chisq.test(survey_q15_contingency)
std_resid <- chisq_result$stdres
print(std_resid)

# correct answer
survey_q15_correct <- survey_q15_contingency[3,]
survey_q15_group_total <- colSums(survey_q15_contingency)
prop.test(survey_q15_correct, survey_q15_group_total)
```
Pairwise proportion test
```{r}
pairwise.prop.test(
  x = survey_q15_contingency[3, ],
  n = colSums(survey_q15_contingency),
  p.adjust.method = "bonferroni" # or "holm", "BH"
)
```


Plot proportion bar plot across different groups
```{r}
survey_q15_prop  <- as.data.frame(survey_q15_contingency)
# rename columns
names(survey_q15_prop) <- c("Qxx.15", "Group", "Count")
# add a labelled column
survey_q15_prop <- survey_q15_prop %>%
  mutate(Qxx.15_label = case_when(
    Qxx.15 == "1" ~ "1-bigger upside risk",
    Qxx.15 == "2" ~ "2-bigger downside risk",
    Qxx.15 == "3" ~ "3-equal risks on both sides"
  ))
# calculate proportions within each group
survey_q15_prop <- survey_q15_prop %>%
  group_by(Group) %>%
  mutate(Proportion = Count / sum(Count))
ggplot(survey_q15_prop, aes(x = as.factor(`Qxx.15_label`), y = Proportion, fill = Group)) + geom_col(position = "dodge") +
  # facet_wrap(~Group)+
  labs(
    title = "Qxx.15 Answer Propotion Plot across Groups",
    x = "Response",
    y = "Proportion"
  ) +
   scale_fill_brewer(palette = "Set2")+
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
Plot the histogram including all participants
```{r}
# histogram including all participants
ggplot(survey_q15, aes(x = q15_value)) +
  geom_histogram(binwidth = 1, fill = "steelblue", color = "white") +
  # facet_wrap(~ group) +
  labs(title = "Qxx.15 Answer Bar Chart",
       x = "Qxx.15",
       y = "Count") +
  scale_x_continuous(breaks = seq(0, max(survey_q15$q15_value, na.rm = TRUE), by = 1)) +
  theme_minimal()
```
## Qxx.17 Self-reported likelihood of exactly 2.6%
How likely do you think it is that the inflation will be exactly 2.6%?\
*ascending value-increasing likelihood*\
Variable: treat as continuous\
Method: Kruskal-Wallis test\
**Result: Fail to reject the null hypothesis. The overall distribution is skewed towards unlikely.**
```{r}
# combine data from different groups
survey_q17 <- data.frame()
survey_q17_list <- list("Q4.17_1","Q6.17_1", "Q8.17_1", "Q10.17_1", "Q12.17_1")
for (i in seq_along(group_list)) {
  df <- group_list[[i]]
  col <- survey_q17_list[[i]]
  temp_table <- df[, c(col, "group")]
  names(temp_table) <- c("q17_value", "group")
  survey_q17 <- rbind(survey_q17, temp_table)
}
survey_q17$q17_value <- as.numeric(survey_q17$q17_value)

#initial check
summary(survey_q17$q17_value)

```
Summary Table
```{r}
survey_q17_summary <- survey_q17 %>% 
  group_by(group) %>%
  summarise(
    median = median(q17_value, na.rm = TRUE),
    IQR    = IQR(q17_value,   na.rm = TRUE),  # same as Q3 − Q1
    Q1     = quantile(q17_value, 0.25, na.rm = TRUE), 
    Q3     = quantile(q17_value, 0.75, na.rm = TRUE)
  )
print(survey_q17_summary)
```

KW test
```{r}
# check normality --> the data is not normally distributed
# shapiro.test(survey_q17$q17_value)

# run Kruskal-Wallis test
kruskal_test <- kruskal.test(q17_value ~ group, data = survey_q17)
print(kruskal_test)
# Effect size
kw_es  <- kruskal_effsize(q17_value ~ group, data = survey_q17, ci = TRUE)
print(kw_es)
```

Plot the distribution of different groups
```{r}
# histogram including all participants
ggplot(survey_q17, aes(x = q17_value)) +
  geom_histogram(binwidth = 1, fill = "steelblue", color = "white") +
    geom_text(
    stat      = "count",
    aes(label = scales::percent(after_stat(count / total_respondents), accuracy = 0.1)),
    position  = position_dodge(width = 0.9),
    vjust     = -0.5,
    size      = 3
  ) +
  # facet_wrap(~ group) +
  scale_y_continuous(
    expand = expansion(mult = c(0, 0.2)))+
  labs(title = "Qxx.17 Self-reported likelihood of exactly 2.6% distribution",
       x = "Responses",
       y = "Count") +
  scale_x_continuous(breaks = as.numeric(names(likelihood_labels)), 
                     labels = likelihood_labels) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Grouped bar-style histogram
ggplot(survey_q17, aes(x = factor(q17_value), fill = factor(group))) +
  geom_bar(position = "dodge") +
  # facet_wrap(~ group) +
    scale_y_continuous(
    expand = expansion(mult = c(0, 0.2)))+
  # add labels
  scale_x_discrete(labels=likelihood_labels) +
  labs(
    title = "Qxx.17 Self-reported likelihood of exactly 2.6% distribution by group",
    x = "Qxx.17 Response",
    y = "Count",
    fill = "Group"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```
## Qxx.19 Rationale for the likelihood of inflation being exactly 2.6%
What tells you that the inflation in 2026Q2 is likely or unlikely to be exactly 2.6%? (Please select the option that best reflects your belief, even if other answers may also seem reasonable.) - Selected Choice\
Variable: categorical\
Method: contingency table + Not comparable across group\
Function:
```{r}
plot_survey_q19 <- function(survey_data, question_header){
  survey_q19 <- survey_data[, c(question_header, "group")]
  survey_q19_contingency <- table(survey_q19[[question_header]], survey_q19$group)
  
  # visualise the contingency table as a bar plot
  ggplot(as.data.frame(survey_q19_contingency), aes(x = Var1, y = Freq, fill = Var2)) +  geom_text(aes(label = Freq),
                 vjust = -0.25                                                                                  )+
    geom_bar(stat = "identity", position = "dodge") +
    labs(title = paste("Qxx.19 Rationale for the likelihood of inflation being exactly 2.6% -", question_header),
         x = "Response",
         y = "Count",
         fill = "Group") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
}
plot_survey_q19(controlled_group, "Q4.19")
plot_survey_q19(error_bar, "Q6.19")
plot_survey_q19(shaded_bar, "Q8.19")
plot_survey_q19(fanchart_slice, "Q10.19")
plot_survey_q19(bell_curve, "Q12.19")
```


## Qxx.21 Self-reported likelihood of inflation being between 1.9% and 3.3%
How likely do you think it is that the inflation will be between 1.9% and 3.3%?\
*ascending value-increasing likelihood*\
Variable: treat as continuous\
Method: Kruskal-Wallis test\
**Result: Fail to reject the null hypothesis. The majority of respondents think it's quite likely.**
```{r}
# combine data from different groups
survey_q21 <- data.frame()
survey_q21_list <- list("Q4.21_1","Q6.21_1", "Q8.21_1", "Q10.21_1", "Q12.21_1")
for (i in seq_along(group_list)) {
  df <- group_list[[i]]
  col <- survey_q21_list[[i]]
  temp_table <- df[, c(col, "group")]
  names(temp_table) <- c("q21_value", "group")
  survey_q21 <- rbind(survey_q21, temp_table)
}
survey_q21$q21_value <- as.numeric(survey_q21$q21_value)
```

Summary Table
```{r}
survey_q21_summary <- survey_q21 %>% 
  group_by(group) %>%
  summarise(
    median = median(q21_value, na.rm = TRUE),
    IQR    = IQR(q21_value,   na.rm = TRUE),  # same as Q3 − Q1
    Q1     = quantile(q21_value, 0.25, na.rm = TRUE), 
    Q3     = quantile(q21_value, 0.75, na.rm = TRUE)
  )
print(survey_q21_summary)
```
KW test
```{r}
# summary(survey_q21)
# check normality --> the data is not normally distributed
# shapiro.test(survey_q21$q21_value)

# run Kruskal-Wallis test
kruskal_test <- kruskal.test(q21_value ~ group, data = survey_q21)
print(kruskal_test)
# Effect size
kw_es  <- kruskal_effsize(q21_value ~ group, data = survey_q21, ci = TRUE)
print(kw_es)
```
Plot the distribution of different groups
```{r}
# Grouped bar-style histogram
ggplot(survey_q21, aes(x = factor(q21_value), fill = factor(group))) +
  geom_bar(position = "dodge") +
  # facet_wrap(~ group) +
  # add labels
  scale_x_discrete(labels=likelihood_labels) +
  labs(
    title = "Qxx.21 Self-reported likelihood of inflation being between 1.9% and 3.3% distribution by group",
    x = "Qxx.21 Response",
    y = "Count",
    fill = "Group"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Plot bar chart including all participants
```{r}
# histogram including all participants
ggplot(survey_q21, aes(x = q21_value)) +
  geom_histogram(binwidth = 1, fill = "steelblue", color = "white") +
  # facet_wrap(~ group) +
  labs(title = "Qxx.21 Self-reported likelihood of inflation being between 1.9% and 3.3% distribution",
       x = "Qxx.21",
       y = "Count") +
  scale_x_continuous(breaks = as.numeric(names(likelihood_labels)), 
                     labels = likelihood_labels) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
## ! Qxx.22 Self-reported likelihood of inflation being between 3.3% and 5.6%
How likely do you think it is that the inflation will be between 3.3% and 5.6%?\
*ascending value-increasing likelihood*\
Variable: treat as continuous\
Method: Kruskal-Wallis test\
**Result: The distribution of shaded bar group and bell curve show statistical difference. Near half of the respondents think it's quite unlikely.**
```{r}
# combine data from different groups
survey_q22 <- data.frame()
survey_q22_list <- list("Q4.22_1","Q6.22_1", "Q8.22_1", "Q10.22_1", "Q12.22_1")
for (i in seq_along(group_list)) {
  df <- group_list[[i]]
  col <- survey_q22_list[[i]]
  temp_table <- df[, c(col, "group")]
  names(temp_table) <- c("q22_value", "group")
  survey_q22 <- rbind(survey_q22, temp_table)
}
survey_q22$q22_value <- as.numeric(survey_q22$q22_value)
summary(survey_q22$q22_value)

```

Summary Table
```{r}
survey_q22_summary <- survey_q22 %>% 
  group_by(group) %>%
  summarise(
    median = median(q22_value, na.rm = TRUE),
    IQR    = IQR(q22_value,   na.rm = TRUE),  # same as Q3 − Q1
    Q1     = quantile(q22_value, 0.25, na.rm = TRUE), 
    Q3     = quantile(q22_value, 0.75, na.rm = TRUE),
    mean   = mean(q22_value, na.rm = TRUE),
  )
print(survey_q22_summary)
```
KW test
```{r}
# check normality --> the data is not normally distributed
# shapiro.test(survey_q22$q22_value)

# run Kruskal-Wallis test
kruskal_test <- kruskal.test(q22_value ~ group, data = survey_q22)
print(kruskal_test)

# Effect size
kw_es  <- kruskal_effsize(q22_value ~ group, data = survey_q22, ci = TRUE)
print(kw_es)

# Post-hoc test
dunnTest(q22_value ~ group, data = survey_q22, method = "bonferroni")
```

Plot the distribution of different groups
```{r}
# Grouped bar-style histogram
ggplot(survey_q22, aes(x = factor(q22_value), fill = factor(group))) +
  geom_bar(position = "dodge") +
  # facet_wrap(~ group) +
  # add labels
  scale_x_discrete(labels=likelihood_labels) +
  labs(
    title = "Qxx.22 Self-reported likelihood of inflation being between 3.3% and 5.6% distribution by group",
    x = "Qxx.22 Response",
    y = "Count",
    fill = "Group"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
Plot bar chart including all participants
```{r}
# histogram including all participants
ggplot(survey_q22, aes(x = q22_value)) +
  geom_histogram(binwidth = 1, fill = "steelblue", color = "white") +
  # facet_wrap(~ group) +
  labs(title = "Qxx.22 Self-reported likelihood of inflation being between 3.3% and 5.6% distribution",
       x = "Qxx.22",
       y = "Count") +
  scale_x_continuous(breaks = as.numeric(names(likelihood_labels)), 
                     labels = likelihood_labels) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
## Qxx.23 Self-reported likelihood of inflation being higher than 3%
How likely do you think it is that the inflation will be higher than 3%?\
*ascending value-increasing likelihood*\
Variable: treat as continuous\
Method: Kruskal-Wallis test\
**Result: Fail to reject the null hypothesis. The majority of respondents think it's quite unlikely, but there is no significant difference.**
```{r}
# combine data from different groups
survey_q23 <- data.frame()
survey_q23_list <- list("Q4.23_1","Q6.23_1", "Q8.23_1", "Q10.23_1", "Q12.23_1")
for (i in seq_along(group_list)) {
  df <- group_list[[i]]
  col <- survey_q23_list[[i]]
  temp_table <- df[, c(col, "group")]
  names(temp_table) <- c("q23_value", "group")
  survey_q23 <- rbind(survey_q23, temp_table)
}
survey_q23$q23_value <- as.numeric(survey_q23$q23_value)
summary(survey_q23$q23_value)
```
Summary Table
```{r}
survey_q23_summary <- survey_q23 %>% 
  group_by(group) %>%
  summarise(
    median = median(q23_value, na.rm = TRUE),
    IQR    = IQR(q23_value,   na.rm = TRUE),  # same as Q3 − Q1
    Q1     = quantile(q23_value, 0.25, na.rm = TRUE), 
    Q3     = quantile(q23_value, 0.75, na.rm = TRUE)
  )
print(survey_q23_summary)
```


KW test
```{r}
# check normality --> the data is not normally distributed
# shapiro.test(survey_q23$q23_value)

# initial check
summary(survey_q23)

# run Kruskal-Wallis test
kruskal_test <- kruskal.test(q23_value ~ group, data = survey_q23)
print(kruskal_test)

# Effect size
kw_es  <- kruskal_effsize(q23_value ~ group, data = survey_q23, ci = TRUE)
print(kw_es)
```
Plot the distribution of different groups
```{r}
# Grouped bar-style histogram
ggplot(survey_q23, aes(x = factor(q23_value), fill = factor(group))) +
  geom_bar(position = "dodge") +
  # facet_wrap(~ group) +
  # add labels
  scale_x_discrete(labels=likelihood_labels) +
  labs(
    title = "Qxx.23 Self-reported likelihood of inflation being higher than 3% distribution by group",
    x = "Qxx.23 Response",
    y = "Count",
    fill = "Group"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
Plot bar chart including all participants
```{r}
# histogram including all participants
ggplot(survey_q23, aes(x = q23_value)) +
  geom_histogram(binwidth = 1, fill = "steelblue", color = "white") +
  # facet_wrap(~ group) +
  labs(title = "Qxx.23 Self-reported likelihood of inflation being higher than 3% distribution",
       x = "Qxx.23",
       y = "Count") +
  scale_x_continuous(breaks = as.numeric(names(likelihood_labels)), 
                     labels = likelihood_labels) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```


## ! Qxx.24 Ranking
Based on the inflation forecast provided, please rank the following inflation rates from most likely to least likely to occur: 0.8%, 2.5%, 3.9% and 6.5%. - 0.8%\
*Lower mean rank = more preferred*\
Method: Mean Rank
```{r}
# combine data from different groups
survey_q24 <- controlled_group[, c("Q4.24_1", "Q4.24_2", "Q4.24_3", "Q4.24_4")]
survey_q24 <- as.data.frame(lapply(survey_q24, as.numeric))
mean_rank <- colMeans(survey_q24, na.rm = TRUE)

rank_summary_controlled <- data.frame(
  Item = c("0.8%", "2.5%", "3.9%", "6.5%"),
  MeanRank = mean_rank
)
```
combine into one table
```{r}
# main code
q24_prefixes <- list("Q4.24", "Q6.24", "Q8.24", "Q10.24", "Q12.24")
rank_summary <- data.frame(
  Item = c("0.8%", "2.5%", "3.9%", "6.5%")
)
survey_q24 <- data.frame()

for (i in seq_along(group_list)) {
  group_name <- names(group_list)[i]
  df <- group_list[[i]]
  q_cols <- paste0(q24_prefixes[[i]], "_", 1:4)
  temp_table <- df[, c(q_cols, "group", "treatment")]
  # combine the data
  names(temp_table) <- c("Qxx.24_1", "Qxx.24_2", "Qxx.24_3", "Qxx.24_4", "group", "treatment")
  temp_table[, c("Qxx.24_1", "Qxx.24_2", "Qxx.24_3", "Qxx.24_4")] <-
  lapply(temp_table[, c("Qxx.24_1", "Qxx.24_2", "Qxx.24_3", "Qxx.24_4")], as.numeric)
  survey_q24 <- rbind(survey_q24, temp_table)

  # mean rank
  df <- as.data.frame(lapply(df[,q_cols], as.numeric))
  mean_rank <- colMeans(df, na.rm = TRUE)
  rank_summary[[group_name]] <- mean_rank
}

# overall means
overall_means <- rowMeans(rank_summary[, -1], na.rm = TRUE)
rank_summary <- cbind(rank_summary, overall = overall_means)

  # correct answer
survey_q24_correct_prop <- survey_q24 %>%
  group_by(group) %>%
  summarise(
    total = n(),
    correct = sum(
      Qxx.24_1 == 3 & Qxx.24_2 == 1 & Qxx.24_3 == 2 & Qxx.24_4 == 4,
      na.rm = TRUE
    ),
    proportion_correct = correct / total,
    .groups = "drop"
  )
```
proportion test
```{r}
prop.test(
  x = survey_q24_correct_prop$correct,
  n = survey_q24_correct_prop$total
)
# pairwise proportion test
pairwise.prop.test(
  x = survey_q24_correct_prop$correct,
  n = survey_q24_correct_prop$total,
  p.adjust.method = "bonferroni" # or "holm", "BH"
)
```

Proportion of correct answer
```{r}
survey_q24 <- controlled_group[, c("Q4.24_1", "Q4.24_2", "Q4.24_3", "Q4.24_4")]
survey_q24 <- as.data.frame(lapply(survey_q24, as.numeric))
survey_q24_correct <- survey_q24[survey_q24$Q4.24_1 == 3 & survey_q24$Q4.24_2 == 1 & survey_q24$Q4.24_3 == 2 & survey_q24$Q4.24_4 == 4, ]
proportion_correct <- nrow(survey_q24_correct) / nrow(survey_q24)
print(proportion_correct)
```
Visualisation Proportion
```{r}
ggplot(survey_q24_correct_prop, aes(x = group, y = proportion_correct, fill = group)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = scales::percent(proportion_correct, accuracy = 0.1)), 
            vjust = -0.5, size = 3) +
  labs(
    title = "Qxx.24 Proportion of Correct Answer by Group",
    x = "Group",
    y = "Proportion of Correct Answers"
  ) +
    scale_y_continuous(
    expand = expansion(mult = c(0, 0.2)) 
  ) +
  scale_fill_brewer(palette = "Set2") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Visualisation Ranking
```{r}
df_long <- rank_summary %>% 
  pivot_longer(-Item, names_to = "Group", values_to = "MeanRank") %>% 
  mutate(
    # Order items by their overall best rank (smallest = best)
    Item  = factor(Item, levels = rank_summary %>% arrange(overall) %>% pull(Item)),
    # Keep groups in the order they appear in the data-frame
    Group = factor(Group, levels = names(rank_summary)[-1])
  )

ggplot(df_long, aes(Group, Item, fill = MeanRank)) +
  geom_tile(colour = "white", linewidth = .4) +
  geom_text(aes(label = round(MeanRank, 2)), size = 3) +
  scale_fill_distiller(palette = "Blues", direction = 1, 
                       name = "Mean rank", limits = c(1, 4), 
                       breaks = 1:4) +
  labs(title = "Mean rank by group (1 = Most Likely)") +
  theme_minimal(base_size = 14) +
  theme(panel.grid = element_blank(),
        axis.text.x = element_text(angle = 45, hjust = 1))
```

## Qxx.26 Accuracy of central estimate
On a scale of 1 to 10, where 1 means not accurate at all and 10 means very accurate, how accurate do you think the central estimate in the graph is?\
*1-Not accurate at all; 10-Very accurate*\
Variable: continuous\
Method: ANNOVA test or KW test (depends on whether it's normally distributed)\
**Result: Fail to reject the null hypothesis.**
```{r}
# combine data from different groups
survey_q26 <- data.frame()
survey_q26_list <- list("Q4.26_1","Q6.26_1", "Q8.26_1", "Q10.26_1", "Q12.26_1")
for (i in seq_along(group_list)) {
  df <- group_list[[i]]
  col <- survey_q26_list[[i]]
  temp_table <- df[, c(col, "group", "treatment")]
  names(temp_table) <- c("q26_value", "group", "treatment")
  survey_q26 <- rbind(survey_q26, temp_table)
}
survey_q26$q26_value <- as.numeric(survey_q26$q26_value)
summary(survey_q26$q26_value)
```
Summary Table
```{r}
survey_q26_summary <- survey_q26 %>% 
  group_by(group) %>%
  summarise(
    mean = mean(q26_value, na.rm = TRUE),
    median = median(q26_value, na.rm = TRUE),
    sd = sd(q26_value, na.rm = TRUE),
    IQR    = IQR(q26_value,   na.rm = TRUE),  # same as Q3 − Q1
    Q1     = quantile(q26_value, 0.25, na.rm = TRUE), 
    Q3     = quantile(q26_value, 0.75, na.rm = TRUE)
  )
print(survey_q26_summary)
```

Statistical test
```{r}
# Initial Check
# summary(survey_q26$q26_value)

# check normality --> the data is not normally distributed
# shapiro.test(survey_q26$q26_value)

# run Kruskal-Wallis test
kruskal_test <- kruskal.test(q26_value ~ group, data = survey_q26)
print(kruskal_test)

# Effect size
kw_es  <- kruskal_effsize(q26_value ~ group, data = survey_q26, ci = TRUE)
print(kw_es)
```
Combine the treatment groups
```{r}
kruskal_test <- kruskal.test(q26_value ~ treatment, data = survey_q26)
print(kruskal_test)
```

Plot the distribution of different groups
```{r}
# Grouped bar-style histogram\
ggplot(survey_q26, aes(x = factor(q26_value), fill = factor(group))) +
  geom_bar(position = "dodge") +
  # facet_wrap(~ group) +
  labs(
    title = "Qxx.26 Accuracy of central estimate distribution by group",
    x = "Qxx.26 Response",
    y = "Count",
    fill = "Group"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

## Qxx.27 Certainty of central estimate
On a scale of 1 to 10, where 1 means very uncertain and 10 means very certain, how certain or uncertain do you think the inflation forecast for 2026 Q2 is?\
*1-Very uncertain; 10-Very certain*\
Variable: continuous\
Method: ANNOVA test or KW test (depends on whether it's normally distributed)\
**Result: Fail to reject the null hypothesis. **
```{r}
# combine data from different groups
survey_q27 <- data.frame()
survey_q27_list <- list("Q4.27_1","Q6.27_1", "Q8.27_1", "Q10.27_1", "Q12.27_1")
for (i in seq_along(group_list)) {
  df <- group_list[[i]]
  col <- survey_q27_list[[i]]
  temp_table <- df[, c(col, "group", "treatment")]
  names(temp_table) <- c("q27_value", "group", "treatment")
  survey_q27 <- rbind(survey_q27, temp_table)
}
survey_q27$q27_value <- as.numeric(survey_q27$q27_value)
summary(survey_q27$q27_value)
```
Statistical test
```{r}
# Initial Check
# summary(survey_q27$q27_value)
# check normality --> the data is not normally distributed
# shapiro.test(survey_q27$q27_value)
# run Kruskal-Wallis test
kruskal_test <- kruskal.test(q27_value ~ group, data = survey_q27)
print(kruskal_test)
# Effect size
kw_es  <- kruskal_effsize(q27_value ~ group, data = survey_q27, ci = TRUE)
print(kw_es)
```
Combine the treatment groups
```{r}
kruskal_test <- kruskal.test(q27_value ~ treatment, data = survey_q27)
print(kruskal_test)
```

Summary statistics
```{r}
# Summary statistics
survey_q27_summary <- survey_q27 %>%
  group_by(group) %>%
  summarise(
    mean = mean(q27_value, na.rm = TRUE),
    median = median(q27_value, na.rm = TRUE),
    sd = sd(q27_value, na.rm = TRUE),
    IQR    = IQR(q27_value,   na.rm = TRUE),  # same as Q3 − Q1
    Q1     = quantile(q27_value, 0.25, na.rm = TRUE), 
    Q3     = quantile(q27_value, 0.75, na.rm = TRUE)
  )
print(survey_q27_summary)
```
Plot the distribution of different groups
```{r}
# Grouped bar-style histogram
ggplot(survey_q27, aes(x = factor(q27_value), fill = factor(group))) +
  geom_bar(position = "dodge") +
  facet_wrap(~ group) +
  labs(
    title = "Qxx.27 The distribution of ceartainty/uncertainty of the central estimate by group",
    x = "Qxx.27 Response",
    y = "Count",
    fill = "Group"
  ) +
  theme_minimal()
```


## Qxx.28 Rationale for certainty/uncertainty of the forecast
Why do you think that the forecast is more or less uncertain? (Select all that apply)\
Variable: categorical\
Method: contingency table + Not comparable across group\
Function:
```{r}
plot_survey_q28 <- function(survey_data, question_header){
  survey_q28 <- survey_data %>%
    # select(all_of(question_header), group) %>%
    mutate(
      !!question_header := lapply(
        as.character(.data[[question_header]]),
        function(x) {
          if (is.na(x) || x == "") return(list())
          nums <- strsplit(x, ",")[[1]]
          as.list(as.numeric(trimws(nums)))
        }
      )
    ) %>%
    unnest(cols = all_of(question_header)) %>%
    group_by(group, value = .data[[question_header]]) %>%
    summarise(count = n(), .groups = "drop") %>%
    mutate(
      value = as.numeric(value)
    )
  # plot the bar chart
  ggplot(survey_q28, aes(x = factor(value), y = count, fill = group)) +
    geom_bar(stat = "identity", position = "dodge") +
    geom_text(aes(label = count), vjust = -0.25, position = position_dodge(0.9)) +
    labs(
      title = paste("Qxx.28 Rationale for certainty/uncertainty of the forecast -", question_header),
      x = "Response",
      y = "Count",
      fill = "Group"
    ) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
  # return(survey_q28)
}

plot_survey_q28(controlled_group, "Q4.28")
```

## Qxx.29 Representativeness of the uncertainty
On a scale of 1 to 10, where 1 means not representative at all and 10 means very representative, how representative do you think the uncertainty being communicated is (i.e., how well the given information reflects the true variability or uncertainty of the forecast?)\
*1-Not representative at all; 10-Very representative*\
Variable: continuous\
Method: ANNOVA test or KW test (depends on whether it's normally distributed)\
**Result: Fail to reject the null hypothesis.**
```{r}
# combine data from different groups
survey_q29 <- data.frame()
survey_q29_list <- list("Q4.29_1","Q6.29_1", "Q8.29_1", "Q10.29_1", "Q12.29_1")
for (i in seq_along(group_list)) {
  df <- group_list[[i]]
  col <- survey_q29_list[[i]]
  temp_table <- df[, c(col, "group", "treatment")]
  names(temp_table) <- c("q29_value", "group", "treatment")
  survey_q29 <- rbind(survey_q29, temp_table)
}
survey_q29$q29_value <- as.numeric(survey_q29$q29_value)
```

Statistical test
```{r}
# Initial Check
# summary(survey_q29$q29_value)
# check normality --> the data is not normally distributed
# shapiro.test(survey_q29$q29_value)
# run Kruskal-Wallis test
kruskal_test <- kruskal.test(q29_value ~ group, data = survey_q29)
print(kruskal_test)

# Effect size
kw_es  <- kruskal_effsize(q29_value ~ group, data = survey_q29, ci = TRUE)
print(kw_es)

```
Combine the treatment groups
```{r}
kruskal_test <- kruskal.test(q29_value ~ treatment, data = survey_q29)
print(kruskal_test)
```

Summary statistics
```{r}
# Summary statistics
survey_q29_summary <- survey_q29 %>%
  group_by(group) %>%
  summarise(
    mean = mean(q29_value, na.rm = TRUE),
    median = median(q29_value, na.rm = TRUE),
    sd = sd(q29_value, na.rm = TRUE),
    IQR    = IQR(q29_value,   na.rm = TRUE),  # same as Q3 − Q1
    Q1     = quantile(q29_value, 0.25, na.rm = TRUE), 
    Q3     = quantile(q29_value, 0.75, na.rm = TRUE)
  )
```
Plot the distribution of different groups
```{r}
# Grouped bar-style histogram
ggplot(survey_q29, aes(x = factor(q29_value), fill = factor(group))) +
  geom_bar(position = "dodge") +
  # facet_wrap(~ group) +
  labs(
    title = "Qxx.29 The distribution of representativeness of the uncertainty by group",
    x = "Qxx.29 Response",
    y = "Count",
    fill = "Group"
  ) +
  theme_minimal()
```

## ! Qxx.30 Readability of the Forecast
On a scale of 1 to 10, where 1 means very difficult and 10 means very easy, how easy or difficult do you find the graph to understand?\
*1-Very difficult; 10-Very easy*\
Variable: continuous\
Method: ANNOVA test or KW test (depends on whether it's normally distributed)\
**Result: There are statistical difference between control group vs. fan chart slice group; control group vs. bell curve; error bar group vs. bell curve group.**
```{r}
# combine data from different groups
survey_q30 <- data.frame()
survey_q30_list <- list("Q4.30_1","Q6.30_1", "Q8.30_1", "Q10.30_1", "Q12.30_1")
for (i in seq_along(group_list)) {
  df <- group_list[[i]]
  col <- survey_q30_list[[i]]
  temp_table <- df[, c(col, "group","treatment")]
  names(temp_table) <- c("q30_value", "group", "treatment")
  survey_q30 <- rbind(survey_q30, temp_table)
}
survey_q30$q30_value <- as.numeric(survey_q30$q30_value)
```

Statistical test
```{r}
# Initial Check
# summary(survey_q30$q30_value)
# check normality --> the data is not normally distributed
# shapiro.test(survey_q30$q30_value)
# run Kruskal-Wallis test
kruskal_test <- kruskal.test(q30_value ~ group, data = survey_q30)
print(kruskal_test)

# Effect size
kw_es  <- kruskal_effsize(q30_value ~ group, data = survey_q30, ci = TRUE)
print(kw_es)

# Post-hoc test
dunnTest(q30_value ~ group, data = survey_q30, method = "bonferroni")
```
Summary statistics
```{r}
# Summary statistics
survey_q30_summary <- survey_q30 %>%
  group_by(group) %>%
  summarise(
    mean = mean(q30_value, na.rm = TRUE),
    median = median(q30_value, na.rm = TRUE),
    sd = sd(q30_value, na.rm = TRUE),
    IQR    = IQR(q30_value,   na.rm = TRUE),  # same as Q3 − Q1
    Q1     = quantile(q30_value, 0.25, na.rm = TRUE), 
    Q3     = quantile(q30_value, 0.75, na.rm = TRUE)
  )
```

Plot the distribution of different groups
```{r}
# Grouped bar-style histogram
ggplot(survey_q30, aes(x = factor(q30_value), fill = factor(group))) +
  geom_bar(position = "dodge") +
  # facet_wrap(~ group) +
  labs(
    title = "Qxx.30 The distribution of readability of the forecast by group",
    x = "Qxx.30 Response",
    y = "Count",
    fill = "Group"
  ) +
  theme_minimal()
```
density plot
```{r}
# Density plot
ggplot(survey_q30, aes(x = q30_value, fill = group)) +
  geom_density(alpha = 0.5) +
  labs(
    title = "Qxx.30 Density Plot of Readability of the Forecast by Group",
    x = "Qxx.30 Response",
    y = "Density",
    fill = "Group"
  ) +
  theme_minimal()
```

## Qxx.31 Trust of the Forecast
On a scale of 1 to 10, where 1 means you don’t trust the inflation forecast at all and 10 means you fully trust it, how much do you trust the inflation forecast shown in the graph?\
*1-Don't trust at all; 10-Fully trust*\
Variable: continuous\
Method: ANNOVA test or KW test (depends on whether it's normally distributed)\
**Result: Fail to reject the null hypothesis. **
```{r}
# combine data from different groups
survey_q31 <- data.frame()
survey_q31_list <- list("Q4.31_1","Q6.31_1", "Q8.31_1", "Q10.31_1", "Q12.31_1")
for (i in seq_along(group_list)) {
  df <- group_list[[i]]
  col <- survey_q31_list[[i]]
  temp_table <- df[, c(col, "group","treatment")]
  names(temp_table) <- c("q31_value", "group", "treatment")
  survey_q31 <- rbind(survey_q31, temp_table)
}
survey_q31$q31_value <- as.numeric(survey_q31$q31_value)
summary(survey_q31$q31_value)
```

Statistical test
```{r}
# Initial Check
# summary(survey_q31$q31_value)

# check normality --> the data is not normally distributed
# shapiro.test(survey_q31$q31_value)

# run Kruskal-Wallis test
kruskal_test <- kruskal.test(q31_value ~ group, data = survey_q31)
print(kruskal_test)

# Effect size
kw_es  <- kruskal_effsize(q31_value ~ group, data = survey_q31, ci = TRUE)
print(kw_es)
```
Combine the treatment groups
```{r}
kruskal_test <- kruskal.test(q31_value ~ treatment, data = survey_q31)
print(kruskal_test)
```

Summary statistics
```{r}
# Summary statistics
survey_q31_summary <- survey_q31 %>%
  group_by(group) %>%
  summarise(
    mean = mean(q31_value, na.rm = TRUE),
    median = median(q31_value, na.rm = TRUE),
    sd = sd(q31_value, na.rm = TRUE),
    IQR    = IQR(q31_value,   na.rm = TRUE),  # same as Q3 − Q1
    Q1     = quantile(q31_value, 0.25, na.rm = TRUE), 
    Q3     = quantile(q31_value, 0.75, na.rm = TRUE)
    
  )
print(survey_q31_summary)
```

Plot the distribution of different groups
```{r}
# Grouped bar-style histogram
ggplot(survey_q31, aes(x = factor(q31_value), fill = factor(group))) +
  geom_bar(position = "dodge") +
  # facet_wrap(~ group) +
  labs(
    title = "Qxx.31 The distribution of trust of the forecast by group",
    x = "Qxx.31 Response",
    y = "Count",
    fill = "Group"
  ) +
  theme_minimal()
```
# Skewed Data <a name="skewed-data"></a>
## Qxx.33 Probability of higher than 3%
Based on the inflation forecast provided, what do you think is the probability of inflation ending up higher than 3%?\
Definitive Correct Answer - 5\
Variable: categorical\
Method: contingency table & proportion test\
**Result: There is no statistical difference across different groups and the largest proportion of participants can understand the probability correctly, but only account for 28% of the entire respondents. **
```{r}
# combine data from different groups
survey_q33 <- data.frame()
survey_q33_list <- list("Q6.33","Q8.33", "Q10.33", "Q12.33")
for (i in seq_along(skewed_group_list)) {
  df <- skewed_group_list[[i]]
  col <- survey_q33_list[[i]]
  temp_table <- df[, c(col, "group")]
  names(temp_table) <- c("q33_value", "group")
  survey_q33 <- rbind(survey_q33, temp_table)
}
survey_q33$q33_value <- as.numeric(survey_q33$q33_value)
```

Test the proportion of correct answer
```{r}
survey_q33_contingency <- table(survey_q33$q33_value, survey_q33$group)
print(survey_q33_contingency)
survey_q33_correct <- survey_q33_contingency[5,]
survey_q33_group_total <- colSums(survey_q33_contingency)
prop.test(survey_q33_correct, survey_q33_group_total)
```
Plot probability of higher than 3% (proportion bar plot across different groups)
```{r}
survey_q33_prop  <- as.data.frame(survey_q33_contingency)
# rename columns
names(survey_q33_prop) <- c("Qxx.33", "Group", "Count")
# add a labelled column
survey_q33_prop <- survey_q33_prop %>%
  mutate(Qxx.33_label = case_when(
    Qxx.33 == "1" ~ "1-More than 60%",
    Qxx.33 == "2" ~ "3-40-50%",
    Qxx.33 == "3" ~ "4-30-40%",
    Qxx.33 == "4" ~ "5-Less than 30%",
    Qxx.33 == "5" ~ "2-50-60%"
  ))
# calculate proportions within each group
survey_q33_prop <- survey_q33_prop %>%
  group_by(Group) %>%
  mutate(Proportion = Count / sum(Count))
ggplot(survey_q33_prop, aes(x = as.factor(`Qxx.33_label`), y = Proportion, fill = Group)) + geom_col(position = "dodge") +
  # facet_wrap(~Group)+
  labs(
    title = "Qxx.33 Answer Propotion Plot across Groups",
    x = "Response",
    y = "Proportion"
  ) +
   scale_fill_brewer(palette = "Set2")+
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
Plot the histogram including all participants
```{r}
# force order for graph
survey_q33 <- survey_q33 %>%
  mutate(
    q33_value_re = factor(
      q33_value,
      levels = c(1, 5, 2, 3, 4)
    )
  )
# histogram including all participants
ggplot(survey_q33, aes(x = q33_value_re)) +
  geom_bar(fill = "steelblue", color = "white") +
  labs(
    title = "Qxx.33 Responses (forced 1-5-2-3-4 order)",
    x     = "Qxx.33",
    y     = "Count"
  ) +
  theme_minimal()

```
## Qxx.34 Self-reported likelihood of inflation being higher than 3%
How likely do you think it is that the inflation will be higher than 3%?\
*ascending value-increasing likelihood*\
Variable: treat as continuous\
Method: Kruskal-Wallis test\
**Result: Fail to reject the null hypothesis. The majority of respondents think it's quite likely.**
```{r}
# combine data from different groups
survey_q34 <- data.frame()
survey_q34_list <- list("Q6.34_1","Q8.34_1", "Q10.34_1", "Q12.34_1")
for (i in seq_along(skewed_group_list)) {
  df <- skewed_group_list[[i]]
  col <- survey_q34_list[[i]]
  temp_table <- df[, c(col, "group")]
  names(temp_table) <- c("q34_value", "group")
  survey_q34 <- rbind(survey_q34, temp_table)
}
survey_q34$q34_value <- as.numeric(survey_q34$q34_value)
```
Summary Table
```{r}
survey_q34_summary <- survey_q34 %>% 
  group_by(group) %>%
  summarise(
    median = median(q34_value, na.rm = TRUE),
    IQR    = IQR(q34_value,   na.rm = TRUE),  # same as Q3 − Q1
    Q1     = quantile(q34_value, 0.25, na.rm = TRUE), 
    Q3     = quantile(q34_value, 0.75, na.rm = TRUE),
    mean   = mean(q34_value, na.rm = TRUE)
  )
print(survey_q34_summary)
```


KW test
```{r}
# check normality --> the data is not normally distributed
# shapiro.test(survey_q34$q34_value)

# run Kruskal-Wallis test
kruskal_test <- kruskal.test(q34_value ~ group, data = survey_q34)
print(kruskal_test)
```
Plot the distribution of different groups
```{r}
# Grouped bar-style histogram
ggplot(survey_q34, aes(x = factor(q34_value), fill = factor(group))) +
  geom_bar(position = "dodge") +
  # facet_wrap(~ group) +
  # add labels
  scale_x_discrete(labels=likelihood_labels) +
  labs(
    title = "Qxx.34 Self-reported likelihood of inflation being higher than 3% distribution by group",
    x = "Qxx.34 Response",
    y = "Count",
    fill = "Group"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
Plot bar chart including all participants
```{r}
# histogram including all participants
ggplot(survey_q34, aes(x = q34_value)) +
  geom_histogram(binwidth = 1, fill = "steelblue", color = "white") +
  # facet_wrap(~ group) +
  labs(title = "Qxx.34 Self-reported likelihood of inflation being higher than 3% distribution",
       x = "Qxx.34",
       y = "Count") +
  scale_x_continuous(breaks = as.numeric(names(likelihood_labels)), 
                     labels = likelihood_labels) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
## Qxx.35 Ranking for 26Q3
Based on the inflation forecast provided, please rank the following inflation rates from most likely to least likely to occur: 1.1%, 2.6%, 3.3% and 4.1%. - 4.1%\
*Lower mean rank = more preferred*\
Method: Mean Rank
```{r}
q35_prefixes <- list("Q6.35", "Q8.35", "Q10.35", "Q12.35")
rank_summary_skewed <- data.frame(
  Item = c("1.1%", "2.6%", "3.3%", "4.1%")
)
survey_q35 <- data.frame()
for (i in seq_along(skewed_group_list)) {
  group_name <- names(skewed_group_list)[i]
  df <- skewed_group_list[[i]]
  q_cols <- paste0(q35_prefixes[[i]], "_", 5:8)
  temp_table <- df[, c(q_cols, "group")]
  # combine the data
  names(temp_table) <- c("Qxx.35_5", "Qxx.35_6", "Qxx.35_7", "Qxx.35_8", "group")
  temp_table[, c("Qxx.35_5", "Qxx.35_6", "Qxx.35_7", "Qxx.35_8")] <-
    lapply(temp_table[, c("Qxx.35_5", "Qxx.35_6", "Qxx.35_7", "Qxx.35_8")], as.numeric)
  survey_q35 <- rbind(survey_q35, temp_table)

  # mean rank
  df <- as.data.frame(lapply(df[,q_cols], as.numeric))
  mean_rank <- colMeans(df, na.rm = TRUE)
  rank_summary_skewed[[group_name]] <- mean_rank
}
# overall means
overall_means <- rowMeans(rank_summary_skewed[, -1], na.rm = TRUE)
rank_summary_skewed <- cbind(rank_summary_skewed, Overall = overall_means)
# correct answer
survey_q35_correct_prop <- survey_q35 %>%
  group_by(group) %>%
  summarise(
    total = n(),
    correct = sum(
      Qxx.35_5 == 4 & Qxx.35_6 == 1 & Qxx.35_7 == 2 & Qxx.35_8 == 3,
      na.rm = TRUE
    ),
    proportion_correct = correct / total,
    .groups = "drop"
  )

```
proportion test
```{r}
prop.test(
  x = survey_q35_correct_prop$correct,
  n = survey_q35_correct_prop$total
)
```
Visualisation Proportion
```{r}
ggplot(survey_q35_correct_prop, aes(x = group, y = proportion_correct, fill = group)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = scales::percent(proportion_correct, accuracy = 0.1)), 
            vjust = -0.5, size = 3) +
  labs(
    title = "Qxx.35 Proportion of Correct Answer by Group",
    x = "Group",
    y = "Proportion of Correct Answers"
  ) +
    scale_y_continuous(
    expand = expansion(mult = c(0, 0.2)) 
  ) +
  scale_fill_brewer(palette = "Set2") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
Visualisation Ranking
```{r}
df_long_skewed <- rank_summary_skewed %>% 
  pivot_longer(-Item, names_to = "Group", values_to = "MeanRank") %>% 
  mutate(
    # Order items by their overall best rank (smallest = best)
    Item  = factor(Item, levels = rank_summary_skewed %>% arrange(Overall) %>% pull(Item)),
    # Keep groups in the order they appear in the data-frame
    Group = factor(Group, levels = names(rank_summary_skewed)[-1])
  )

ggplot(df_long_skewed, aes(Group, Item, fill = MeanRank)) +
  geom_tile(colour = "white", linewidth = .4) +
  geom_text(aes(label = round(MeanRank, 2)), size = 3) +
  scale_fill_distiller(palette = "Blues", direction = 1, 
                       name = "Mean rank", limits = c(1, 4), 
                       breaks = 1:4) +
  labs(title = "Mean rank by group (1 = Most Likely)") +
  theme_minimal(base_size = 14) +
  theme(panel.grid = element_blank(),
        axis.text.x = element_text(angle = 45, hjust = 1))

```

## Qxx.36 Deviation from central estimate
Based on the inflation forecast provided,  do you think there is a higher risk of inflation exceeding the central estimate or of being less than this central estimate?\
Definitive Correct Answer - 1\
Variable: categorical\
Method: contingency table & proportion test\
**Result: There is no statistical difference across group. 68% of respondents can understand there is bigger upside risk. **
```{r}
# combine data from different groups
survey_q36 <- data.frame()
survey_q36_list <- list("Q6.36","Q8.36", "Q10.36", "Q12.36")
for (i in seq_along(skewed_group_list)) {
  df <- skewed_group_list[[i]]
  col <- survey_q36_list[[i]]
  temp_table <- df[, c(col, "group")]
  names(temp_table) <- c("q36_value", "group")
  survey_q36 <- rbind(survey_q36, temp_table)
}
survey_q36$q36_value <- as.numeric(survey_q36$q36_value)
```

Contingency table
```{r}
survey_q36_contingency <- table(survey_q36$q36_value, survey_q36$group)
print(survey_q36_contingency)
chisq_result <- chisq.test(survey_q36_contingency)
print(chisq_result)
```
Test the proportion of correct answer
```{r}
survey_q36_correct <- survey_q36_contingency[1,]
survey_q36_group_total <- colSums(survey_q36_contingency)
prop.test(survey_q36_correct, survey_q36_group_total)
```

Plot proportion bar plot across different groups
```{r}
survey_q36_prop  <- as.data.frame(survey_q36_contingency)
# rename columns
names(survey_q36_prop) <- c("Qxx.36", "Group", "Count")
# add a labelled column
survey_q36_prop <- survey_q36_prop %>%
  mutate(Qxx.36_label = case_when(
    Qxx.36 == "1" ~ "1-bigger upside risk",
    Qxx.36 == "2" ~ "2-bigger downside risk",
    Qxx.36 == "3" ~ "3-equal risks on both sides"
  ))
# calculate proportions within each group
survey_q36_prop <- survey_q36_prop %>%
  group_by(Group) %>%
  mutate(Proportion = Count / sum(Count))
ggplot(survey_q36_prop, aes(x = as.factor(`Qxx.36_label`), y = Proportion, fill = Group)) + geom_col(position = "dodge") +
  # facet_wrap(~Group)+
  labs(
    title = "Qxx.36 Answer Propotion Plot across Groups",
    x = "Response",
    y = "Proportion"
  ) +
   scale_fill_brewer(palette = "Set2")+
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Plot the histogram including all participants
```{r}
# histogram including all participants
ggplot(survey_q36, aes(x = q36_value)) +
  geom_histogram(binwidth = 1, fill = "steelblue", color = "white") +
  # facet_wrap(~ group) +
  labs(title = "Qxx.36 Answer Bar Chart",
       x = "Qxx.36",
       y = "Count") +
  scale_x_continuous(breaks = seq(0, max(survey_q36$q36_value, na.rm = TRUE), by = 1)) +
  theme_minimal()
```

## ? Qxx.37 Risk of ending outside
If the actual inflation ends up outside the black line, which side is more likely, based on the uncertainty depicted in the graph?\
Definitive Correct Answer - 1\
Variable: categorical\
Method: contingency table & proportion test\
**Result: 63% respondents think if the actual inflation ends up outside, it's more likely to be on the upper side. **
```{r}
# combine data from different groups
survey_q37 <- data.frame()
survey_q37_list <- list("Q6.37","Q8.37", "Q10.37", "Q12.37")
for (i in seq_along(skewed_group_list)) {
  df <- skewed_group_list[[i]]
  col <- survey_q37_list[[i]]
  temp_table <- df[, c(col, "group")]
  names(temp_table) <- c("q37_value", "group")
  survey_q37 <- rbind(survey_q37, temp_table)
}
survey_q37$q37_value <- as.numeric(survey_q37$q37_value)
```

Contingency table
```{r}
survey_q37_contingency <- table(survey_q37$q37_value, survey_q37$group)
print(survey_q37_contingency)

# chisq_result <- chisq.test(survey_q37_contingency)
# print(chisq_result)

# Test the proportion of correct answer
survey_q37_correct <- survey_q37_contingency[1,]
survey_q37_group_total <- colSums(survey_q37_contingency)
prop.test(survey_q37_correct, survey_q37_group_total)

# pairwise proportion test
pairwise.prop.test(
  x = survey_q37_contingency[1,],
  n = colSums(survey_q37_contingency),
  p.adjust.method = "bonferroni" # or "holm", "BH"
)
```
Plot proportion bar plot across different groups
```{r}
survey_q37_prop  <- as.data.frame(survey_q37_contingency)
# rename columns
names(survey_q37_prop) <- c("Qxx.37", "Group", "Count")
# add a labelled column
survey_q37_prop <- survey_q37_prop %>%
  mutate(Qxx.37_label = case_when(
    Qxx.37 == "1" ~ "1-More likely to be on the upper side",
    Qxx.37 == "2" ~ "2-More likely to be on the lower side",
    Qxx.37 == "3" ~ "3-Equal chances of being on either side"
  ))
# calculate proportions within each group
survey_q37_prop <- survey_q37_prop %>%
  group_by(Group) %>%
  mutate(Proportion = Count / sum(Count))
ggplot(survey_q37_prop, aes(x = as.factor(`Qxx.37_label`), y = Proportion, fill = Group)) + geom_col(position = "dodge") +
  # facet_wrap(~Group)+
  labs(
    title = "Qxx.37 Answer Propotion Plot across Groups",
    x = "Response",
    y = "Proportion"
  ) +
   scale_fill_brewer(palette = "Set2")+
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
Plot the histogram including all participants
```{r}
# histogram including all participants
ggplot(survey_q37, aes(x = q37_value)) +
  geom_histogram(binwidth = 1, fill = "steelblue", color = "white") +
  # facet_wrap(~ group) +
  labs(title = "Qxx.37 Answer Bar Chart",
       x = "Qxx.37",
       y = "Count") +
  scale_x_continuous(breaks = seq(0, max(survey_q37$q37_value, na.rm = TRUE), by = 1)) +
  theme_minimal()
```




# Decision-making <a name="decision-making"></a>
## D.3 Investment Decision
Which bond would you choose to invest in?\
Variable: categorical\
Method: contingency table & proportion test\
**Result: Fail to reject the null hypothesis. **
```{r}
# combine data from different groups
survey_d3 <- data.frame()
survey_d3_list <- list("Q5.3","Q7.3", "Q9.3", "Q11.3", "Q13.3")
for (i in seq_along(group_list)) {
  df <- group_list[[i]]
  col <- survey_d3_list[[i]]
  temp_table <- df[, c(col, "group","treatment")]
  names(temp_table) <- c("d3_value", "group", "treatment")
  survey_d3 <- rbind(survey_d3, temp_table)
}
survey_d3$d3_value <- as.numeric(survey_d3$d3_value)
```
Contingency table
```{r}
survey_d3_contingency <- table(survey_d3$d3_value, survey_d3$group)
print(survey_d3_contingency)
# chi-squared test
chisq.test(survey_d3_contingency)
# prop.test
# survey_d3_correct <- survey_d3_contingency[1,]
# survey_d3_group_total <- colSums(survey_d3_contingency)
# prop.test(survey_d3_correct, survey_d3_group_total)
```
Combine all treatment groups (p-value = 0.7548)
```{r}
survey_d3_contingency <- table(survey_d3$d3_value, survey_d3$treatment)
print(survey_d3_contingency)
# chi-squared test
chisq.test(survey_d3_contingency)

```

Plot proportion bar plot across different groups
```{r}
survey_d3_prop  <- as.data.frame(survey_d3_contingency)
# rename columns
names(survey_d3_prop) <- c("D.3", "Group", "Count")
# add a labelled column
survey_d3_prop <- survey_d3_prop %>%
  mutate(D.3_label = case_when(
    D.3 == "1" ~ "A. Nominal Bond",
    D.3 == "2" ~ "B. Inflation-Protected Bond"
  ))
# calculate proportions within each group
survey_d3_prop <- survey_d3_prop %>%
  group_by(Group) %>%
  mutate(Proportion = Count / sum(Count))
ggplot(survey_d3_prop, aes(x = as.factor(`D.3_label`), y = Proportion, fill = Group)) + geom_col(position = "dodge") +
  # facet_wrap(~Group)+
  labs(
    title = "D.3 Answer Propotion Plot across Groups",
    x = "Response",
    y = "Proportion"
  ) +
   scale_fill_brewer(palette = "Set2")+
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
Plot pie chart including all participants
```{r}
survey_d3_summary <- survey_d3_prop %>%
  group_by(`D.3_label`) %>%
  summarise(total_count = sum(Count), .groups = "drop") %>%
  mutate(proportion = total_count / sum(total_count),
         `D.3_graph_label` = paste0(`D.3_label`, " (", round(proportion * 100, 2), " %)"))
ggplot(survey_d3_summary, aes(x = "",y = proportion, fill = `D.3_graph_label`)) +
  geom_col(width = 1) +
  coord_polar(theta = "y") +
  labs(title = "D.3 Investment Decision Summary Pie Chart",
       x = "",
       y = "") +
  theme_minimal() +
  theme(axis.text.x = element_blank())
```
## D.4 Confidence in decision-making
On a scale of 1 to 10, where 1 means not confident at all and 10 means very confident, how confident  are you in making the decision?\
*1-Not confident at all; 10-Very confident*\
Variable: continuous\
Method: ANNOVA test or KW test (depends on whether it's normally distributed)\
**Result: Fail to reject the null hypothesis. **
```{r}
# combine data from different groups
survey_d4 <- data.frame()
survey_d4_list <- list("Q5.4_1","Q7.4_1", "Q9.4_1", "Q11.4_1", "Q13.4_1")
for (i in seq_along(group_list)) {
  df <- group_list[[i]]
  col <- survey_d4_list[[i]]
  temp_table <- df[, c(col, "group","treatment")]
  names(temp_table) <- c("d4_value", "group", "treatment")
  survey_d4 <- rbind(survey_d4, temp_table)
}
survey_d4$d4_value <- as.numeric(survey_d4$d4_value)
```
Statistical test (p-value = 0.1333)
```{r}
# Initial Check
# summary(survey_d4$d4_value)
# check normality --> the data is not normally distributed
# shapiro.test(survey_d4$d4_value)

# run Kruskal-Wallis test
kruskal_test <- kruskal.test(d4_value ~ group, data = survey_d4)
print(kruskal_test)
```
Combine all treatment groups (p-value = 0.5824)
```{r}
# run Kruskal-Wallis test
kruskal_test <- kruskal.test(d4_value ~ treatment, data = survey_d4)
print(kruskal_test)

survey_d4_test <- survey_d4 %>%
  group_by(treatment) %>%
  summarise(
    mean = mean(d4_value, na.rm = TRUE))
```


Summary statistics
```{r}
# Summary statistics
survey_d4_summary <- survey_d4 %>%
  group_by(group) %>%
  summarise(
    mean = mean(d4_value, na.rm = TRUE),
    median = median(d4_value, na.rm = TRUE),
    sd = sd(d4_value, na.rm = TRUE),
    IQR    = IQR(d4_value,   na.rm = TRUE),  # same as Q3 − Q1
    Q1     = quantile(d4_value, 0.25, na.rm = TRUE),
    Q3     = quantile(d4_value, 0.75, na.rm = TRUE)
  )
```
Plot the distribution of different groups
```{r}
# Grouped bar-style histogram
ggplot(survey_d4, aes(x = factor(d4_value), fill = factor(group))) +
  geom_bar(position = "dodge") +
  # facet_wrap(~ group) +
  labs(
    title = "D.4 The distribution of confidence in decision-making by group",
    x = "D.4 Response",
    y = "Count",
    fill = "Group"
  ) +
  theme_minimal()
```
## D.6 Considering nominal bond
If the probability of inflation being low (≤ 3%) is greater than the following percentages, I would consider investing in the nominal bond:\
Variable: categorical\
Method: contingency table & chi-squared test\
**Result: Fail to reject the null hypothesis.**
```{r}
# combine data from different groups
survey_d6 <- data.frame()
survey_d6_list <- list("Q5.6","Q7.6", "Q9.6", "Q11.6", "Q13.6")
for (i in seq_along(group_list)) {
  df <- group_list[[i]]
  col <- survey_d6_list[[i]]
  temp_table <- df[, c(col, "group")]
  names(temp_table) <- c("d6_value", "group")
  survey_d6 <- rbind(survey_d6, temp_table)
}
survey_d6$d6_value <- as.numeric(survey_d6$d6_value)
```
Contingency table
```{r}
survey_d6_contingency <- table(survey_d6$d6_value, survey_d6$group)
print(survey_d6_contingency)
# run chi-squared test
chisq_result <- chisq.test(survey_d6_contingency)
print(chisq_result)
```
Plot proportion bar plot across different groups
```{r}
survey_d6_prop  <- as.data.frame(survey_d6_contingency)
# rename columns
names(survey_d6_prop) <- c("D.6", "Group", "Count")
# add a labelled column
survey_d6_prop <- survey_d6_prop %>%
  mutate(D.6_label = case_when(
    D.6 == "1" ~ "1-40%",
    D.6 == "2" ~ "2-50%",
    D.6 == "3" ~ "3-60%",
    D.6 == "4" ~ "4-do not think about probability",
    D.6 == "5" ~ "5-always choose an inflation-protected bond",
    D.6 == "7" ~ "6-70%",
    D.6 == "8" ~ "7-80%"
  ))
# calculate proportions within each group
survey_d6_prop <- survey_d6_prop %>%
  group_by(Group) %>%
  mutate(Proportion = Count / sum(Count))
ggplot(survey_d6_prop, aes(x = as.factor(`D.6_label`), y = Proportion, fill = Group)) + geom_col(position = "dodge") +
  # facet_wrap(~Group)+
  labs(
    title = "D.6 Answer Propotion Plot across Groups",
    x = "Response",
    y = "Proportion"
  ) +
   scale_fill_brewer(palette = "Set2")+
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
Plot the histogram including all participants
```{r}
# histogram including all participants
ggplot(survey_d6, aes(x = d6_value)) +
  geom_histogram(binwidth = 1, fill = "steelblue", color = "white") +
  # facet_wrap(~ group) +
  labs(title = "D.6 Histogram",
       x = "D.6",
       y = "Count") +
  scale_x_continuous(breaks = seq(0, max(survey_d6$d6_value, na.rm = TRUE), by = 1)) +
  theme_minimal()
```
## D.7 Considering inflation-protected bond
If the probability of inflation being high (> 3%) is greater than the following percentages, I would consider investing in the inflation-protected bond:\
Variable: categorical\
Method: contingency table & chi-squared test\
*Result: Fail to reject the null hypothesis.**
```{r}
# combine data from different groups
survey_d7 <- data.frame()
survey_d7_list <- list("Q5.7","Q7.7", "Q9.7", "Q11.7", "Q13.7")
for (i in seq_along(group_list)) {
  df <- group_list[[i]]
  col <- survey_d7_list[[i]]
  temp_table <- df[, c(col, "group")]
  names(temp_table) <- c("d7_value", "group")
  survey_d7 <- rbind(survey_d7, temp_table)
}
survey_d7$d7_value <- as.numeric(survey_d7$d7_value)
```
Contingency table
```{r}
survey_d7_contingency <- table(survey_d7$d7_value, survey_d7$group)
print(survey_d7_contingency)
# run chi-squared test
chisq_result <- chisq.test(survey_d7_contingency)
print(chisq_result)
```
Plot proportion bar plot across different groups
```{r}
survey_d7_prop  <- as.data.frame(survey_d7_contingency)
# rename columns
names(survey_d7_prop) <- c("D.7", "Group", "Count")
# add a labelled column
survey_d7_prop <- survey_d7_prop %>%
  mutate(D.7_label = case_when(
    D.7 == "1" ~ "1-40%",
    D.7 == "2" ~ "2-50%",
    D.7 == "3" ~ "3-60%",
    D.7 == "4" ~ "4-do not think about probability",
    D.7 == "5" ~ "5-always choose a nominal bond",
    D.7 == "7" ~ "6-70%",
    D.7 == "8" ~ "7-80%"
  ))
# calculate proportions within each group
survey_d7_prop <- survey_d7_prop %>%
  group_by(Group) %>%
  mutate(Proportion = Count / sum(Count))
ggplot(survey_d7_prop, aes(x = as.factor(`D.7_label`), y = Proportion, fill = Group)) + geom_col(position = "dodge") +
  # facet_wrap(~Group)+
  labs(
    title = "D.7 Answer Propotion Plot across Groups",
    x = "Response",
    y = "Proportion"
  ) +
   scale_fill_brewer(palette = "Set2")+
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
Plot the histogram including all participants
```{r}
# histogram including all participants
ggplot(survey_d7, aes(x = d7_value)) +
  geom_histogram(binwidth = 1, fill = "steelblue", color = "white") +
  # facet_wrap(~ group) +
  labs(title = "D.7 Histogram",
       x = "D.7",
       y = "Count") +
  scale_x_continuous(breaks = seq(0, max(survey_d7$d7_value, na.rm = TRUE), by = 1)) +
  theme_minimal()
```
## D.8 Impact on Desicion-making
Considering the payoff for the Nominal Bond, which of the following has a larger impact on your decision-making?\
Variable: categorical\
Method: contingency table & chi-squared test\
**Result: Fail to reject the null hypothesis.**
```{r}
# combine data from different groups
survey_d8 <- data.frame()
survey_d8_list <- list("Q5.8","Q7.8", "Q9.8", "Q11.8", "Q13.8")
for (i in seq_along(group_list)) {
  df <- group_list[[i]]
  col <- survey_d8_list[[i]]
  temp_table <- df[, c(col, "group")]
  names(temp_table) <- c("d8_value", "group")
  survey_d8 <- rbind(survey_d8, temp_table)
}
survey_d8$d8_value <- as.numeric(survey_d8$d8_value)
```
Contingency table
```{r}
survey_d8_contingency <- table(survey_d8$d8_value, survey_d8$group)
print(survey_d8_contingency)
# run chi-squared test
chisq_result <- chisq.test(survey_d8_contingency)
print(chisq_result)
```
Plot proportion bar plot across different groups
```{r}
survey_d8_prop  <- as.data.frame(survey_d8_contingency)
# rename columns
names(survey_d8_prop) <- c("D.8", "Group", "Count")
# add a labelled column
survey_d8_prop <- survey_d8_prop %>%
  mutate(D.8_label = case_when(
    D.8 == "1" ~ "1-potential loss",
    D.8 == "2" ~ "2-potential gain",
    D.8 == "3" ~ "3-potential loss and gain have the same impact"
  ))
# calculate proportions within each group
survey_d8_prop <- survey_d8_prop %>%
  group_by(Group) %>%
  mutate(Proportion = Count / sum(Count))
ggplot(survey_d8_prop, aes(x = as.factor(`D.8_label`), y = Proportion, fill = Group)) + geom_col(position = "dodge") +
  # facet_wrap(~Group)+
  labs(
    title = "D.8 Answer Propotion Plot across Groups",
    x = "Response",
    y = "Proportion"
  ) +
   scale_fill_brewer(palette = "Set2")+
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
Plot the histogram including all participants
```{r}
# histogram including all participants
ggplot(survey_d8, aes(x = d8_value)) +
  geom_histogram(binwidth = 1, fill = "steelblue", color = "white") +
  # facet_wrap(~ group) +
  labs(title = "D.8 Histogram",
       x = "D.8",
       y = "Count") +
  scale_x_continuous(breaks = seq(0, max(survey_d8$d8_value, na.rm = TRUE), by = 1)) +
  theme_minimal()
```

## D.9 Effectiveness of the graph for decision-making
On a scale of 1 to 10, where 1 means the forecast was not effective at all and 10 means it was very effective, how effective do you think the forecast was in assisting your decision-making?\
*1-Not effective at all; 10-Very effective*\
Variable: continuous\
Method: ANNOVA test or KW test (depends on whether it's normally distributed)\
**Result: At least one group is statistically significant than others. **
```{r}
# combine data from different groups
survey_d9 <- data.frame()
survey_d9_list <- list("Q5.9_1","Q7.9_1", "Q9.9_1", "Q11.9_1", "Q13.9_1")
for (i in seq_along(group_list)) {
  df <- group_list[[i]]
  col <- survey_d9_list[[i]]
  temp_table <- df[, c(col, "group")]
  names(temp_table) <- c("d9_value", "group")
  survey_d9 <- rbind(survey_d9, temp_table)
}
survey_d9$d9_value <- as.numeric(survey_d9$d9_value)
```
Statistical test
```{r}
# Initial Check
# summary(survey_d9$d9_value)
# check normality --> the data is not normally distributed
# shapiro.test(survey_d9$d9_value)

# run Kruskal-Wallis test
kruskal_test <- kruskal.test(d9_value ~ group, data = survey_d9)
print(kruskal_test)
# Post-hoc test
dunnTest(d9_value ~ group, data = survey_d9, method = "bonferroni")
```
Summary statistics
```{r}
# Summary statistics
survey_d9_summary <- survey_d9 %>%
  group_by(group) %>%
  summarise(
    mean = mean(d9_value, na.rm = TRUE),
    median = median(d9_value, na.rm = TRUE),
    sd = sd(d9_value, na.rm = TRUE),
    IQR    = IQR(d9_value,   na.rm = TRUE),  # same as Q3 − Q1
    Q1     = quantile(d9_value, 0.25, na.rm = TRUE),
    Q3     = quantile(d9_value, 0.75, na.rm = TRUE)
  )
print(survey_d9_summary)
```

Plot the distribution of different groups
```{r}
# Grouped bar-style histogram
ggplot(survey_d9, aes(x = factor(d9_value), fill = factor(group))) +
  geom_bar(position = "dodge") +
  # facet_wrap(~ group) +
  labs(
    title = "D.9 The distribution of effectiveness of the graph for decision-making by group",
    x = "D.9 Response",
    y = "Count",
    fill = "Group"
  ) +
  theme_minimal()
```


## ? D.12 Skewed Investment Decision
Which bond would you choose to invest in?\
Variable: categorical\
Method: contingency table & chi-squared test\
**Result: There is significant difference in at least one group.**
```{r}
# combine data from different groups
survey_d12 <- data.frame()
survey_d12_list <- list("Q7.12", "Q9.12", "Q11.12", "Q13.12")
for (i in seq_along(skewed_group_list)) {
  df <- skewed_group_list[[i]]
  col <- survey_d12_list[[i]]
  temp_table <- df[, c(col, "group")]
  names(temp_table) <- c("d12_value", "group")
  survey_d12 <- rbind(survey_d12, temp_table)
}
survey_d12$d12_value <- as.numeric(survey_d12$d12_value)
```
Contingency table
```{r}
survey_d12_contingency <- table(survey_d12$d12_value, survey_d12$group)
print(survey_d12_contingency)
# run chi-squared test
chisq_result <- chisq.test(survey_d12_contingency)
# print(chisq_result)
std_resid <- chisq_result$stdres
print(std_resid)

# pairwise proportion test
pairwise.prop.test(
  x = survey_d12_contingency[2,],
  n = colSums(survey_d12_contingency),
  p.adjust.method = "bonferroni" # or "holm", "BH"
)
```
Plot proportion bar plot across different groups
```{r}
survey_d12_prop  <- as.data.frame(survey_d12_contingency)
# rename columns
names(survey_d12_prop) <- c("D.12", "Group", "Count")
# add a labelled column
survey_d12_prop <- survey_d12_prop %>%
  mutate(D.12_label = case_when(
    D.12 == "1" ~ "A. Nominal Bond",
    D.12 == "2" ~ "B. Inflation-Protected Bond"
  ))
# calculate proportions within each group
survey_d12_prop <- survey_d12_prop %>%
  group_by(Group) %>%
  mutate(Proportion = Count / sum(Count))
ggplot(survey_d12_prop, aes(x = as.factor(`D.12_label`), y = Proportion, fill = Group)) + geom_col(position = "dodge") +
  # facet_wrap(~Group)+
  labs(
    title = "D.12 Answer Propotion Plot across Groups",
    x = "Response",
    y = "Proportion"
  ) +
   scale_fill_brewer(palette = "Set2")+
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
Plot pie chart including all participants
```{r}
survey_d12_summary <- survey_d12_prop %>%
  group_by(`D.12_label`) %>%
  summarise(total_count = sum(Count), .groups = "drop") %>%
  mutate(proportion = total_count / sum(total_count),
         `D.12_graph_label` = paste0(`D.12_label`, " (", round(proportion * 100, 2), " %)"))
ggplot(survey_d12_summary, aes(x = "",y = proportion, fill = `D.12_graph_label`)) +
  geom_col(width = 1) +
  coord_polar(theta = "y") +
  labs(title = "D.12 Investment Decision Summary Pie Chart",
       x = "",
       y = "") +
  theme_minimal() +
  theme(axis.text.x = element_blank())
```
## D.13 Skewed Confidentce in decision-making
On a scale of 1 to 10, where 1 means not confident at all and 10 means very confident, how confident  are you in making the decision?\
*1-Not confident at all; 10-Very confident*\
Variable: continuous\
Method: ANNOVA test or KW test (depends on whether it's normally distributed)\
**Result: Fail to reject the null hypothesis.**
```{r}
# combine data from different groups
survey_d13 <- data.frame()
survey_d13_list <- list("Q7.13_1", "Q9.13_1", "Q11.13_1", "Q13.13_1")
for (i in seq_along(skewed_group_list)) {
  df <- skewed_group_list[[i]]
  col <- survey_d13_list[[i]]
  temp_table <- df[, c(col, "group")]
  names(temp_table) <- c("d13_value", "group")
  survey_d13 <- rbind(survey_d13, temp_table)
}
survey_d13$d13_value <- as.numeric(survey_d13$d13_value)
```
Statistical test
```{r}
# Initial Check
# summary(survey_d13$d13_value)
# check normality --> the data is not normally distributed
# shapiro.test(survey_d13$d13_value)

# run Kruskal-Wallis test
kruskal_test <- kruskal.test(d13_value ~ group, data = survey_d13)
print(kruskal_test)

```
Summary statistics
```{r}
# Summary statistics
survey_d13_summary <- survey_d13 %>%
  group_by(group) %>%
  summarise(
    mean = mean(d13_value, na.rm = TRUE),
    median = median(d13_value, na.rm = TRUE),
    sd = sd(d13_value, na.rm = TRUE)
  )
```
Plot the distribution of different groups
```{r}
# Grouped bar-style histogram
ggplot(survey_d13, aes(x = factor(d13_value), fill = factor(group))) +
  geom_bar(position = "dodge") +
  # facet_wrap(~ group) +
  labs(
    title = "D.13 The distribution of confidence in decision-making by group",
    x = "D.13 Response",
    y = "Count",
    fill = "Group"
  ) +
  theme_minimal()
```


# Cross-tabulation
## Current Inflation Knowledge vs. Inflation Forecast Knowledge
## Skewed Data vs. Unskewed Data ( understanding and decision making)
## For people who can correctly understand the probability (? which), what decision do they make? --> I am thinking propotion test see reduced probability. 
## Does familarity with the graph type affect understanding and the decision?



# Statistical Testing <a name="statistical-testing"></a>
## Basics
Type I error- false positives (saying there's a difference when there isn't) Usually set to 0.05\\
Type II error: risk of a false negative (failing to detect a real effect). β = 1 – power = 0.20 \\
Power = 1 - β = 0.80 (80% chance of detecting a true effect)\\
The classical null‑hypothesis test (p-value) only tells whether the data are incompatible with zero effect. Pairwise comparison for effect size with confidence interval shows whether the results big enough to matter. -- see if the interval include the Cohen’s d value we set before.
## Power Caluculation 
Cohen’s d / Hedges’ g are pairwise numbers, whereas Cohen’s f describe omnibus gap across ≥3 groups\\
 f (≈d/2)
They are calculated by (effect)/standard deviation.\
This can be estimated through pilot studies 
```{r}
library(pwr)

N_total <- 309
sens <- pwr.anova.test(k = 5,
                       n = N_total / 5*1.15,   # ~10–15 % cushion for KW test
                       sig.level = 0.05,
                       power = 0.80)      # f left NULL
sens
```

## Chi-squared test
### Post-hoc test
1. Standardized residuals
```{r eval=FALSE, include=FALSE}
chisq_result <- chisq.test(q3_4_contingency)
std_resid <- chisq_result$stdres
print(std_resid)
```
Cells with absolute value > ~2 (or > 1.96 for 95% confidence)indicate  contributing most to the overall chi-squared\

2. Pairwise proportion tests: can only compare one value
```{r eval=FALSE, include=FALSE}
pairwise.prop.test(
  x = q3_4_contingency[1,],  # counts per group
  n = colSums(q3_4_contingency),                     # total per group
  p.adjust.method = "bonferroni"                     # or "holm", "BH"
)
```


## ANOVA test
ANOVA only compares the means of the groups.\
### Assumptions of ANOVA
1. Normality of residuals within each group: If p-value<0.05, the data is not normally distributed\
```{r eval=FALSE, include=FALSE}
shapiro.test(df$value)
```

2. Homogeneity of variances across groups
```{r}{r eval=FALSE, include=FALSE}
# Check the assumption of equal variances (homogeneity of variance) across groups 
# If p< 0.05, we can reject the null hypothesis of equal variances, meaning the variances are significantly different across groups
bartlett.test(`Q3.2` ~ group, data = age_table) # if data is normally distributed
# Levene's test for homogeneity of variance if data may not be normally distributed
library(car)
leveneTest(value ~ group, data = time_duration_table)
```
### Post-hoc test
If ANOVA is significant, we can perform post-hoc tests to determine which groups are significantly different from each other.\
```{r}{r eval=FALSE, include=FALSE}
# post-hoc test
tukey_test <- TukeyHSD(anova_test)
print(tukey_test)

```

> Null hypothesis (H₀): All group means are equal\
> Alternative hypothesis (H₁): At least one group mean is different

## Kruskal-Wallis test
(non-parametric test)\
when the dependent variable is continuous or ordinal\
when the assumptions of one-way ANOVA are not met: normality and equal variances

e.g., Likert-scale responses (ordinal) 
### Post-hoc test
```{r eval=FALSE, include=FALSE}
library(FSA)

dunnTest(value ~ group, data = df, method = "bonferroni")
# 
```

## Propotion test -prop.test()
- prop.test(): at least one group differs
<font color="red">continuity correction??</font>
The prop.test() function only supports alternative = "less" or "greater" when comparing a single proportion to a hypothesized value — not when comparing multiple groups.
- pairwise.prop.test():  identifying which specific pairs of groups differ significantly in their proportions, choose the p.adjust.method = "holm" or "bonferroni" or "BH"
